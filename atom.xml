<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>YMLiang</title>
  <icon>https://www.gravatar.com/avatar/949b3d2d55d796bff0595b9b4a58fdde</icon>
  <subtitle>Never forget why you started</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-05-06T10:17:15.987Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>YMLiang</name>
    <email>18135479521@163.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>leetCode 155 最小栈</title>
    <link href="http://yoursite.com/2019/05/06/leetCode-155-%E6%9C%80%E5%B0%8F%E6%A0%88/"/>
    <id>http://yoursite.com/2019/05/06/leetCode-155-最小栈/</id>
    <published>2019-05-06T10:04:32.000Z</published>
    <updated>2019-05-06T10:17:15.987Z</updated>
    
    <content type="html"><![CDATA[<pre><code>设计一个支持 push，pop，top 操作，并能在常数时间内检索到最小元素的栈。push(x) -- 将元素 x 推入栈中。pop() -- 删除栈顶的元素。top() -- 获取栈顶元素。getMin() -- 检索栈中的最小元素。</code></pre><a id="more"></a><pre><code>示例:MinStack minStack = new MinStack();minStack.push(-2);minStack.push(0);minStack.push(-3);minStack.getMin();   --&gt; 返回 -3.minStack.pop();minStack.top();      --&gt; 返回 0.minStack.getMin();   --&gt; 返回 -2.</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">class MinStack &#123;</span><br><span class="line">    //声明栈</span><br><span class="line">    private Stack&lt;Integer&gt; stack;</span><br><span class="line">    //声明初始最小值为Integer.MAX_VALUE保证第一个push的值必定毕它小则可以设定第一个push的值为最小值</span><br><span class="line">    private int min = Integer.MAX_VALUE;</span><br><span class="line">    /** initialize your data structure here. */</span><br><span class="line"></span><br><span class="line">    public MinStack() &#123;</span><br><span class="line">        //新建栈</span><br><span class="line">        stack = new Stack&lt;&gt;();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void push(int x) &#123;</span><br><span class="line">        //判断如果push的值小于等于min值则将之前的最小值入栈，min设置为当前最小值，之后将当前最小值入栈</span><br><span class="line">        // &gt;= 中的 等于是为了避免出现相同值的情况 比如 0,1,0</span><br><span class="line">        if(min&gt;=x)&#123;</span><br><span class="line">            stack.push(min);</span><br><span class="line">            min = x;</span><br><span class="line">        &#125;</span><br><span class="line">        stack.push(x);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void pop() &#123;</span><br><span class="line">        //判断pop的值是否和当前最小值相等，如果相等则将上一次push的值设为最小值(因为pop后栈顶元素为上一次入栈的最小值)，整体思路就是每次遇到最小值时将上一次的最小值push，之后push当前最小值，pop的时候也是同样，如果pop的值等于最小值则将最小值设置为上一次push入的值，注意pop的时候，只要执行了pop()方法，栈顶元素就出栈了，则当前最小值出栈，此时栈顶元素为上一次push的最小值，所以可以直接设置为最小值(即 min = stack.pop())</span><br><span class="line">        if(stack.pop() == min)&#123;</span><br><span class="line">            min = stack.pop();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public int top() &#123;</span><br><span class="line">        //打印栈顶元素</span><br><span class="line">        return stack.peek();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public int getMin() &#123;</span><br><span class="line">        //直接返回设定的最小值</span><br><span class="line">        return min;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line">* 忽略这段</span><br><span class="line">* Your MinStack object will be instantiated and called as such:</span><br><span class="line">* MinStack obj = new MinStack();</span><br><span class="line">* obj.push(x);</span><br><span class="line">* obj.pop();</span><br><span class="line">* int param_3 = obj.top();</span><br><span class="line">* int param_4 = obj.getMin();</span><br><span class="line">*/</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;设计一个支持 push，pop，top 操作，并能在常数时间内检索到最小元素的栈。

push(x) -- 将元素 x 推入栈中。
pop() -- 删除栈顶的元素。
top() -- 获取栈顶元素。
getMin() -- 检索栈中的最小元素。
&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
      <category term="leetcode" scheme="http://yoursite.com/categories/leetcode/"/>
    
    
      <category term="leetcode" scheme="http://yoursite.com/tags/leetcode/"/>
    
  </entry>
  
  <entry>
    <title>linux高级命令</title>
    <link href="http://yoursite.com/2019/05/06/linux%E9%AB%98%E7%BA%A7%E5%91%BD%E4%BB%A4/"/>
    <id>http://yoursite.com/2019/05/06/linux高级命令/</id>
    <published>2019-05-06T06:48:25.000Z</published>
    <updated>2019-05-06T06:56:06.294Z</updated>
    
    <content type="html"><![CDATA[<h3 id="awk"><a href="#awk" class="headerlink" title="awk"></a>awk</h3><pre><code>awk是行处理器: 相比较屏幕处理的优点，在处理庞大文件时不会出现内存溢出或是处理缓慢的问题，通常用来格式化文本信息awk处理过程: 依次对每一行进行处理，然后输出awk命令形式:awk [-F|-f|-v] ‘BEGIN{} //{command1; command2} END{}’ file[-F|-f|-v]   大参数，-F指定分隔符，-f调用脚本，-v定义变量 var=value&apos;  &apos;          引用代码块BEGIN   初始化代码块，在对每一行进行处理之前，初始化代码，主要是引用全局变量，设置FS分隔符//           匹配代码块，可以是字符串或正则表达式{}           命令代码块，包含一条或多条命令；          多条命令使用分号分隔END      结尾代码块，在对每一行进行处理之后再执行的代码块，主要是进行最终计算或输出结尾摘要信息特殊要点:$0           表示整个当前行$1           每行第一个字段NF          字段数量变量NR          每行的记录号，多文件记录递增FNR        与NR类似，不过多文件记录不递增，每个文件都从1开始\t            制表符\n           换行符FS          BEGIN时定义分隔符RS       输入的记录分隔符， 默认为换行符(即文本是按一行一行输入)~            匹配，与==相比不是精确比较!~           不匹配，不精确比较==         等于，必须全部相等，精确比较!=           不等于，精确比较&amp;&amp;　     逻辑与||             逻辑或+            匹配时表示1个或1个以上/[0-9][0-9]+/   两个或两个以上数字/[0-9][0-9]*/    一个或一个以上数字FILENAME 文件名OFS      输出字段分隔符， 默认也是空格，可以改为制表符等ORS        输出的记录分隔符，默认为换行符,即处理结果也是一行一行输出到屏幕-F&apos;[:#/]&apos;   定义三个分隔符print &amp; $0print 是awk打印指定内容的主要命令awk &apos;{print}&apos;  /etc/passwd   ==   awk &apos;{print $0}&apos;  /etc/passwd  awk &apos;{print &quot; &quot;}&apos; /etc/passwd                                           //不输出passwd的内容，而是输出相同个数的空行，进一步解释了awk是一行一行处理文本awk &apos;{print &quot;a&quot;}&apos;   /etc/passwd                                        //输出相同个数的a行，一行只有一个a字母awk -F&quot;:&quot; &apos;{print $1}&apos;  /etc/passwd awk -F: &apos;{print $1; print $2}&apos;   /etc/passwd                   //将每一行的前二个字段，分行输出，进一步理解一行一行处理文本awk  -F: &apos;{print $1,$3,$6}&apos; OFS=&quot;\t&quot; /etc/passwd        //输出字段1,3,6，以制表符作为分隔符-f指定脚本文件awk -f script.awk  fileBEGIN{FS=&quot;:&quot;}{print $1}               //效果与awk -F&quot;:&quot; &apos;{print $1}&apos;相同,只是分隔符使用FS在代码自身中指定awk &apos;BEGIN{X=0} /^$/{ X+=1 } END{print &quot;I find&quot;,X,&quot;blank lines.&quot;}&apos; test I find 4 blank lines.ls -l|awk &apos;BEGIN{sum=0} !/^d/{sum+=$5} END{print &quot;total size is&quot;,sum}&apos;                    //计算文件大小total size is 17487-F指定分隔符$1 指指定分隔符后，第一个字段，$3第三个字段， \t是制表符一个或多个连续的空格或制表符看做一个定界符，即多个空格看做一个空格awk -F&quot;:&quot; &apos;{print $1}&apos;  /etc/passwdawk -F&quot;:&quot; &apos;{print $1 $3}&apos;  /etc/passwd                       //$1与$3相连输出，不分隔awk -F&quot;:&quot; &apos;{print $1,$3}&apos;  /etc/passwd                       //多了一个逗号，$1与$3使用空格分隔awk -F&quot;:&quot; &apos;{print $1 &quot; &quot; $3}&apos;  /etc/passwd                  //$1与$3之间手动添加空格分隔awk -F&quot;:&quot; &apos;{print &quot;Username:&quot; $1 &quot;\t\t Uid:&quot; $3 }&apos; /etc/passwd       //自定义输出  awk -F: &apos;{print NF}&apos; /etc/passwd                                //显示每行有多少字段awk -F: &apos;{print $NF}&apos; /etc/passwd                              //将每行第NF个字段的值打印出来awk -F: &apos;NF==4 {print }&apos; /etc/passwd                       //显示只有4个字段的行awk -F: &apos;NF&gt;2{print $0}&apos; /etc/passwd                       //显示每行字段数量大于2的行awk &apos;{print NR,$0}&apos; /etc/passwd                                 //输出每行的行号awk -F: &apos;{print NR,NF,$NF,&quot;\t&quot;,$0}&apos; /etc/passwd      //依次打印行号，字段数，最后字段值，制表符，每行内容awk -F: &apos;NR==5{print}&apos;  /etc/passwd                         //显示第5行awk -F: &apos;NR==5 || NR==6{print}&apos;  /etc/passwd       //显示第5行和第6行route -n|awk &apos;NR!=1{print}&apos;                                       //不显示第一行//匹配代码块//纯字符匹配   !//纯字符不匹配   ~//字段值匹配    !~//字段值不匹配   ~/a1|a2/字段值匹配a1或a2   awk &apos;/mysql/&apos; /etc/passwdawk &apos;/mysql/{print }&apos; /etc/passwdawk &apos;/mysql/{print $0}&apos; /etc/passwd                   //三条指令结果一样awk &apos;!/mysql/{print $0}&apos; /etc/passwd                  //输出不匹配mysql的行awk &apos;/mysql|mail/{print}&apos; /etc/passwdawk &apos;!/mysql|mail/{print}&apos; /etc/passwdawk -F: &apos;/mail/,/mysql/{print}&apos; /etc/passwd         //区间匹配awk &apos;/[2][7][7]*/{print $0}&apos; /etc/passwd               //匹配包含27为数字开头的行，如27，277，2777...awk -F: &apos;$1~/mail/{print $1}&apos; /etc/passwd           //$1匹配指定内容才显示awk -F: &apos;{if($1~/mail/) print $1}&apos; /etc/passwd     //与上面相同awk -F: &apos;$1!~/mail/{print $1}&apos; /etc/passwd          //不匹配awk -F: &apos;$1!~/mail|mysql/{print $1}&apos; /etc/passwd        IF语句必须用在{}中，且比较内容用()扩起来awk -F: &apos;{if($1~/mail/) print $1}&apos; /etc/passwd                                       //简写awk -F: &apos;{if($1~/mail/) {print $1}}&apos;  /etc/passwd                                   //全写awk -F: &apos;{if($1~/mail/) {print $1} else {print $2}}&apos; /etc/passwd            //if...else...条件表达式==   !=   &gt;   &gt;=  awk -F&quot;:&quot; &apos;$1==&quot;mysql&quot;{print $3}&apos; /etc/passwd  awk -F&quot;:&quot; &apos;{if($1==&quot;mysql&quot;) print $3}&apos; /etc/passwd          //与上面相同 awk -F&quot;:&quot; &apos;$1!=&quot;mysql&quot;{print $3}&apos; /etc/passwd                 //不等于awk -F&quot;:&quot; &apos;$3&gt;1000{print $3}&apos; /etc/passwd                      //大于awk -F&quot;:&quot; &apos;$3&gt;=100{print $3}&apos; /etc/passwd                     //大于等于awk -F&quot;:&quot; &apos;$3&lt;1{print $3}&apos; /etc/passwd                            //小于awk -F&quot;:&quot; &apos;$3&lt;=1{print $3}&apos; /etc/passwd                         //小于等于逻辑运算符&amp;&amp;　|| awk -F: &apos;$1~/mail/ &amp;&amp; $3&gt;8 {print }&apos; /etc/passwd         //逻辑与，$1匹配mail，并且$3&gt;8awk -F: &apos;{if($1~/mail/ &amp;&amp; $3&gt;8) print }&apos; /etc/passwdawk -F: &apos;$1~/mail/ || $3&gt;1000 {print }&apos; /etc/passwd       //逻辑或awk -F: &apos;{if($1~/mail/ || $3&gt;1000) print }&apos; /etc/passwd 数值运算awk -F: &apos;$3 &gt; 100&apos; /etc/passwd    awk -F: &apos;$3 &gt; 100 || $3 &lt; 5&apos; /etc/passwd  awk -F: &apos;$3+$4 &gt; 200&apos; /etc/passwdawk -F: &apos;/mysql|mail/{print $3+10}&apos; /etc/passwd                    //第三个字段加10打印 awk -F: &apos;/mysql/{print $3-$4}&apos; /etc/passwd                             //减法awk -F: &apos;/mysql/{print $3*$4}&apos; /etc/passwd                             //求乘积awk &apos;/MemFree/{print $2/1024}&apos; /proc/meminfo                  //除法awk &apos;/MemFree/{print int($2/1024)}&apos; /proc/meminfo           //取整输出分隔符OFSawk &apos;$6 ~ /FIN/ || NR==1 {print NR,$4,$5,$6}&apos; OFS=&quot;\t&quot; netstat.txtawk &apos;$6 ~ /WAIT/ || NR==1 {print NR,$4,$5,$6}&apos; OFS=&quot;\t&quot; netstat.txt        //输出字段6匹配WAIT的行，其中输出每行行号，字段4，5,6，并使用制表符分割字段输出处理结果到文件①在命令代码块中直接输出    route -n|awk &apos;NR!=1{print &gt; &quot;./fs&quot;}&apos;   ②使用重定向进行输出           route -n|awk &apos;NR!=1{print}&apos;  &gt; ./fs格式化输出netstat -anp|awk &apos;{printf &quot;%-8s %-8s %-10s\n&quot;,$1,$2,$3}&apos; printf表示格式输出%格式化输出分隔符-8长度为8个字符s表示字符串类型打印每行前三个字段，指定第一个字段输出字符串类型(长度为8)，第二个字段输出字符串类型(长度为8),第三个字段输出字符串类型(长度为10)netstat -anp|awk &apos;$6==&quot;LISTEN&quot; || NR==1 {printf &quot;%-10s %-10s %-10s \n&quot;,$1,$2,$3}&apos;netstat -anp|awk &apos;$6==&quot;LISTEN&quot; || NR==1 {printf &quot;%-3s %-10s %-10s %-10s \n&quot;,NR,$1,$2,$3}&apos;IF语句awk -F: &apos;{if($3&gt;100) print &quot;large&quot;; else print &quot;small&quot;}&apos; /etc/passwdsmallsmallsmalllargesmallsmallawk -F: &apos;BEGIN{A=0;B=0} {if($3&gt;100) {A++; print &quot;large&quot;} else {B++; print &quot;small&quot;}} END{print A,&quot;\t&quot;,B}&apos; /etc/passwd                                                                                                                 //ID大于100,A加1，否则B加1awk -F: &apos;{if($3&lt;100) next; else print}&apos; /etc/passwd                         //小于100跳过，否则显示awk -F: &apos;BEGIN{i=1} {if(i&lt;NF) print NR,NF,i++ }&apos; /etc/passwd   awk -F: &apos;BEGIN{i=1} {if(i&lt;NF) {print NR,NF} i++ }&apos; /etc/passwd另一种形式awk -F: &apos;{print ($3&gt;100 ? &quot;yes&quot;:&quot;no&quot;)}&apos;  /etc/passwd awk -F: &apos;{print ($3&gt;100 ? $3&quot;:\tyes&quot;:$3&quot;:\tno&quot;)}&apos;  /etc/passwdwhile语句awk -F: &apos;BEGIN{i=1} {while(i&lt;NF) print NF,$i,i++}&apos; /etc/passwd 7 root 17 x 27 0 37 0 47 root 57 /root 6数组netstat -anp|awk &apos;NR!=1{a[$6]++} END{for (i in a) print i,&quot;\t&quot;,a[i]}&apos;netstat -anp|awk &apos;NR!=1{a[$6]++} END{for (i in a) printf &quot;%-20s %-10s %-5s \n&quot;, i,&quot;\t&quot;,a[i]}&apos;9523                               1     9929                               1     LISTEN                            6     7903                               1     3038/cupsd                   1     7913                               1     10837                             1     9833                               1     应用1awk -F: &apos;{print NF}&apos; helloworld.sh                                                       //输出文件每行有多少字段awk -F: &apos;{print $1,$2,$3,$4,$5}&apos; helloworld.sh                                 //输出前5个字段awk -F: &apos;{print $1,$2,$3,$4,$5}&apos; OFS=&apos;\t&apos; helloworld.sh                 //输出前5个字段并使用制表符分隔输出awk -F: &apos;{print NR,$1,$2,$3,$4,$5}&apos; OFS=&apos;\t&apos; helloworld.sh           //制表符分隔输出前5个字段，并打印行号应用2awk -F&apos;[:#]&apos; &apos;{print NF}&apos;  helloworld.sh                                                  //指定多个分隔符: #，输出每行多少字段awk -F&apos;[:#]&apos; &apos;{print $1,$2,$3,$4,$5,$6,$7}&apos; OFS=&apos;\t&apos; helloworld.sh   //制表符分隔输出多字段应用3awk -F&apos;[:#/]&apos; &apos;{print NF}&apos; helloworld.sh                                               //指定三个分隔符，并输出每行字段数awk -F&apos;[:#/]&apos; &apos;{print $1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11,$12}&apos; helloworld.sh     //制表符分隔输出多字段应用4计算/home目录下，普通文件的大小，使用KB作为单位ls -l|awk &apos;BEGIN{sum=0} !/^d/{sum+=$5} END{print &quot;total size is:&quot;,sum/1024,&quot;KB&quot;}&apos;ls -l|awk &apos;BEGIN{sum=0} !/^d/{sum+=$5} END{print &quot;total size is:&quot;,int(sum/1024),&quot;KB&quot;}&apos;         //int是取整的意思应用5统计netstat -anp 状态为LISTEN和CONNECT的连接数量分别是多少netstat -anp|awk &apos;$6~/LISTEN|CONNECTED/{sum[$6]++} END{for (i in sum) printf &quot;%-10s %-6s %-3s \n&quot;, i,&quot; &quot;,sum[i]}&apos;应用6统计/home目录下不同用户的普通文件的总数是多少？ls -l|awk &apos;NR!=1 &amp;&amp; !/^d/{sum[$3]++} END{for (i in sum) printf &quot;%-6s %-5s %-3s \n&quot;,i,&quot; &quot;,sum[i]}&apos;   mysql        199 root           374 统计/home目录下不同用户的普通文件的大小总size是多少？ls -l|awk &apos;NR!=1 &amp;&amp; !/^d/{sum[$3]+=$5} END{for (i in sum) printf &quot;%-6s %-5s %-3s %-2s \n&quot;,i,&quot; &quot;,sum[i]/1024/1024,&quot;MB&quot;}&apos;应用7输出成绩表awk &apos;BEGIN{math=0;eng=0;com=0;printf &quot;Lineno.   Name    No.    Math   English   Computer    Total\n&quot;;printf &quot;------------------------------------------------------------\n&quot;}{math+=$3; eng+=$4; com+=$5;printf &quot;%-8s %-7s %-7s %-7s %-9s %-10s %-7s \n&quot;,NR,$1,$2,$3,$4,$5,$3+$4+$5} END{printf &quot;------------------------------------------------------------\n&quot;;printf &quot;%-24s %-7s %-9s %-20s \n&quot;,&quot;Total:&quot;,math,eng,com;printf &quot;%-24s %-7s %-9s %-20s \n&quot;,&quot;Avg:&quot;,math/NR,eng/NR,com/NR}&apos; test0[root@localhost home]# cat test0 Marry   2143 78 84 77Jack    2321 66 78 45Tom     2122 48 77 71Mike    2537 87 97 95Bob     2415 40 57 62awk手册http://www.chinaunix.net/old_jh/7/16985.html</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;awk&quot;&gt;&lt;a href=&quot;#awk&quot; class=&quot;headerlink&quot; title=&quot;awk&quot;&gt;&lt;/a&gt;awk&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;awk是行处理器: 相比较屏幕处理的优点，在处理庞大文件时不会出现内存溢出或是处理缓慢的问题，通常用来格式化文本信息
      
    
    </summary>
    
      <category term="linux" scheme="http://yoursite.com/categories/linux/"/>
    
    
      <category term="linux" scheme="http://yoursite.com/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>springCloud多模块打包时报错问题</title>
    <link href="http://yoursite.com/2019/04/25/springCloud%E5%A4%9A%E6%A8%A1%E5%9D%97%E6%89%93%E5%8C%85%E6%97%B6%E6%8A%A5%E9%94%99%E9%97%AE%E9%A2%98/"/>
    <id>http://yoursite.com/2019/04/25/springCloud多模块打包时报错问题/</id>
    <published>2019-04-25T07:08:51.000Z</published>
    <updated>2019-04-25T07:41:12.510Z</updated>
    
    <content type="html"><![CDATA[<p>执行mvn clean package spring-boot:repackage，报错如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[ERROR] Failed to execute goal org.springframework.boot:spring-boot-maven-plugin:1.5.3.RELEASE:repackage (default)</span><br><span class="line"> on project webapps-api-bid: Execution default of goal org.springframework.boot:spring-boot-maven-plugin:1.5.3.RELEASE:</span><br><span class="line"> repackage failed: Unable to find main class</span><br></pre></td></tr></table></figure></p><p>错误提示：</p><p><code>repackage failed: Unable to find main class</code><br><a id="more"></a><br>原因：</p><pre><code>多模块打包时，如果项目模块包含common，core等模块，这些模块不需要启动，应把其打成不可执行包来使用那当我们在maven中有多重依赖时，应注意一点，Common打包出来的应该是不可执行的jar包，所以不要在Common的pom中定义spring-boot-maven-plugin插件。项目    yixue（父类工程，定义各模块，指定模块依赖jar版本）|------------------------------|--yixue-admin    后台用户注册||--yixue-course  后台视频管理||--yixue-commom     common工具包，维护工具类，公共类||--yixue-ui    web界面，请求跳转，拦截等||--yixue-eureka   SpringCloud注册</code></pre><p>解决方法：</p><pre><code>common项目中除了必要的依赖包以外，maven打包的插件不要再添加一遍了，因为这个SpringBoot插件会在Maven的package后进行二次打包，目的为了生成可执行jar包，如果C中定义了这个插件，会报错提示没有找到main函数简单来说，如果你的root：`&lt;parent&gt;&lt;/parent&gt;`项目已经添加了`spring-boot-maven-plugin`插件，那么common就别依赖root了，自己包含一些必要的依赖包，之后别手动添加打包插件即可，如果打包还是失败的话，对root项目clean再install一下，之后应该没有什么问题了</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;执行mvn clean package spring-boot:repackage，报错如下：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[ERROR] Failed to execute goal org.springframework.boot:spring-boot-maven-plugin:1.5.3.RELEASE:repackage (default)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; on project webapps-api-bid: Execution default of goal org.springframework.boot:spring-boot-maven-plugin:1.5.3.RELEASE:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; repackage failed: Unable to find main class&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;错误提示：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;repackage failed: Unable to find main class&lt;/code&gt;&lt;br&gt;
    
    </summary>
    
      <category term="springCloud,springboot" scheme="http://yoursite.com/categories/springCloud-springboot/"/>
    
    
      <category term="springCloud,springboot" scheme="http://yoursite.com/tags/springCloud-springboot/"/>
    
  </entry>
  
  <entry>
    <title>SQL分析函数场景实例</title>
    <link href="http://yoursite.com/2019/04/18/SQL%E5%88%86%E6%9E%90%E5%87%BD%E6%95%B0%E5%9C%BA%E6%99%AF%E5%AE%9E%E4%BE%8B/"/>
    <id>http://yoursite.com/2019/04/18/SQL分析函数场景实例/</id>
    <published>2019-04-18T10:51:34.000Z</published>
    <updated>2019-05-15T02:38:37.070Z</updated>
    
    <content type="html"><![CDATA[<h3 id="分析函数"><a href="#分析函数" class="headerlink" title="分析函数"></a>分析函数</h3><ol><li><p>用来排序的函数<br>它和聚合函数的不同之处是对于每个组返回多行<br><code>row_number() over()rank() over()dense_rank() over()first_value() over()</code></p><a id="more"></a><p><a href="https://blog.csdn.net/myflysun/article/details/70477204" target="_blank" rel="noopener">语法:</a></p><p> row_number() over([partition by xxx] [order by xxx]) 返回的是行信息，没有排名<br> rank ( )  over([partition by xxx] [order by xxx]) 返回的相关等级不会跳跃<br> dense_rank ( ) over([partition by xxx] [order by xxx]) 返回的返回的相关等级会跳跃</p></li></ol><p>场景: 查询每个班的第一名的成绩</p><pre><code>SELECT * FROM (select t.name,t.class,t.sroce,rank() over(partition by t.class order by t.sroce desc) mm from T2_TEMP t) where mm = 1;</code></pre><p><code>LagLead</code></p><p><a href="https://blog.csdn.net/pelifymeng2/article/details/70313943" target="_blank" rel="noopener">语法:</a></p><pre><code>lag(exp_str,offset,defval) over(partion by ..order by …)lead(exp_str,offset,defval) over(partion by ..order by …)其中exp_str是字段名Offset是偏移量，即是上1个或上N个的值，假设当前行在表中排在第5行，则offset 为3，则表示我们所要找的数据行就是表中的第2行（即5-3=2）,默认值是1Defval默认值，当两个函数取上N/下N个值，当在表中从当前行位置向前数N行已经超出了表的范围时，lag（）函数将defval这个参数值作为函数的返回值，若没有指定默认值，则返回NULL，那么在数学运算中，总要给一个默认值才不会出错。</code></pre><ol start="2"><li><p>聚合函数</p><pre><code>聚合函数对于每个组只返回一行count、max、min、sum、avg、Variance、StddevCount 用来求有效数据的数量Max 用来求给定数据中最大的那一个数据Min    用来求给定数据中最小的那一个数据Avg    用来求给定数据的平均值Sum 用来求给定数据的总和Variance 用来求给定数据的标准差Stddev 用来求给定数据的方差median 主要用于统计整表或者分组情况下的中位数（限定参数为数值型或日期/时间型），忽略NULL值对于聚合函数，如果给定的值中存在空值的话，oracle将会直接忽略select count(*) from xxx对于聚合函数中可以使用distinct关键字来压缩重复值比如我们想统计总共有多少个部门的话我们如果写Select count(deptno) from emp;将会得到错误的结果。因为实际上有很多重复的值也被计算在内。为了找到正确的答案，你应该这样写。Select count(distinct deptno) from emp;</code></pre></li><li><p><a href="http://www.cnblogs.com/cc11001100/p/9043946.html" target="_blank" rel="noopener">collect函数</a></p></li></ol><p><code>collect_listcollect_set</code></p><p>它们都是将分组中的某列转为一个数组返回，不同的是collect_list不去重而collect_set去重。</p><p>语法: </p><pre><code>collect_list(column_name)collect_set(column_name)有的时候我们想根据A进行分组然后随便取出每个分组中的一个B，代入到这个实验中就是按照用户进行分组，然后随便拿出一个他看过的视频名称即可collect_list(column_name)[0] 和取数组一样简单</code></pre><p>### </p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;分析函数&quot;&gt;&lt;a href=&quot;#分析函数&quot; class=&quot;headerlink&quot; title=&quot;分析函数&quot;&gt;&lt;/a&gt;分析函数&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;用来排序的函数&lt;br&gt;它和聚合函数的不同之处是对于每个组返回多行&lt;br&gt;&lt;code&gt;row_number() over()
rank() over()
dense_rank() over()
first_value() over()&lt;/code&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="sql" scheme="http://yoursite.com/categories/sql/"/>
    
    
      <category term="sql" scheme="http://yoursite.com/tags/sql/"/>
    
  </entry>
  
  <entry>
    <title>springboot踩坑出坑记</title>
    <link href="http://yoursite.com/2019/04/17/springboot%E8%B8%A9%E5%9D%91%E5%87%BA%E5%9D%91%E8%AE%B0/"/>
    <id>http://yoursite.com/2019/04/17/springboot踩坑出坑记/</id>
    <published>2019-04-17T09:57:26.000Z</published>
    <updated>2019-04-25T07:57:20.310Z</updated>
    
    <content type="html"><![CDATA[<p>4月15到4月17我都在把毕设从eclipse重构到IDEA中，springboot最让我头疼的是它的版本问题，因为每一个版本对应的依赖包都有可能出错，这里分享一下如何成功移植用eclipse写的springboot到IDEA中，比较简单的步骤我这里不详细说了，说一下我遇到的一些很难找出问题的地方<br>ps:只是针对于我的项目和我个人水平，大神勿喷嘿嘿<br><a id="more"></a></p><h2 id="springboot-mybatis整合坑"><a href="#springboot-mybatis整合坑" class="headerlink" title="springboot-mybatis整合坑"></a>springboot-mybatis整合坑</h2><ul><li>出现下方错误请查看启动类：XXXApplication 是否扫描到mapper映射文件，声明eclipse和idea不一样，这里eclipse可以跑通，idea中不行<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">***************************</span><br><span class="line">APPLICATION FAILED TO START</span><br><span class="line">***************************</span><br><span class="line"></span><br><span class="line">Description:</span><br><span class="line"></span><br><span class="line">Field chapterDao in cn.yixue.service.ChapterServiceImp required a bean of type &apos;cn.yixue.dao.ChapterMapper&apos; that could not be found.</span><br><span class="line"></span><br><span class="line">The injection point has the following annotations:</span><br><span class="line">    - @org.springframework.beans.factory.annotation.Autowired(required=true)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Action:</span><br><span class="line"></span><br><span class="line">Consider defining a bean of type &apos;cn.yixue.dao.ChapterMapper&apos; in your configuration.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">以上提取出有用的信息：required a bean of type &apos;xxxx&apos; that could not be found.</span><br><span class="line"></span><br><span class="line">代表bean没注入，从bean注入寻找方向，有的人会说我用@Autowired之类的种种，但没扫到，好吧~</span><br></pre></td></tr></table></figure></li></ul><p>解决方法：</p><ol><li><p>在相应的mapper类中加@Mapper标注让springboot根据标注去将mapper注入</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">@Mapper</span><br><span class="line">public interface ChapterMapper &#123;</span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>启动类加<code>@MapperScan(value = &quot;cn.yixue.video.dao&quot;)</code> value 后的包一定要对应到mapper类对应的地方，比如我的mapper在dao下，就是<code>cn.yixue.video.dao</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">@SpringBootApplication</span><br><span class="line">@MapperScan(value = &quot;cn.yixue.video.dao&quot;)</span><br><span class="line">@EnableDiscoveryClient</span><br><span class="line">public class YixueVideoApplication &#123;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        SpringApplication.run(YixueVideoApplication.class, args);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Spring Boot项目中含有Mybatis,打Jar包运行之后,报如下错误:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">***************************</span><br><span class="line">APPLICATION FAILED TO START</span><br><span class="line">***************************</span><br><span class="line"></span><br><span class="line">Description:</span><br><span class="line"></span><br><span class="line">Failed to configure a DataSource: &apos;url&apos; attribute is not specified and no embedded datasource could be configured.</span><br><span class="line"></span><br><span class="line">Reason: Failed to determine a suitable driver class</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Action:</span><br><span class="line"></span><br><span class="line">Consider the following:</span><br><span class="line">    If you want an embedded database (H2, HSQL or Derby), please put it on the classpath.</span><br><span class="line">    If you have database settings to be loaded from a particular profile you may need to activate it (no profiles are currently active).</span><br></pre></td></tr></table></figure></li></ol><p>网上好多解决方案，针对于每个人都不一样，我的应该是打包的时候读不到我的配置文件，需要在<code>pom.xml</code>里面加<code>resourses</code>指定下配置文件，因为eclipse是识别的，Idea可能不会？我也不太知道，反正是加上了，因为好像有Idea读不到我的<code>application.properties</code>或者<code>application.yml</code>文件，我就一次性都配上了，这个大家具体遇到的时候再去搜一下就行，不用刻意的记:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">&lt;build&gt;</span><br><span class="line">&lt;!-- 如果不添加此节点mybatis的mapper.xml文件都会被漏掉。 --&gt;</span><br><span class="line">&lt;resources&gt;</span><br><span class="line">    &lt;resource&gt;</span><br><span class="line">        &lt;directory&gt;src/main/java&lt;/directory&gt;</span><br><span class="line">        &lt;includes&gt;</span><br><span class="line">            &lt;include&gt;**/*.yml&lt;/include&gt;</span><br><span class="line">            &lt;include&gt;**/*.properties&lt;/include&gt;</span><br><span class="line">            &lt;include&gt;**/*.xml&lt;/include&gt;</span><br><span class="line">        &lt;/includes&gt;</span><br><span class="line">        &lt;filtering&gt;false&lt;/filtering&gt;</span><br><span class="line">    &lt;/resource&gt;</span><br><span class="line">    &lt;resource&gt;</span><br><span class="line">        &lt;directory&gt;src/main/resources&lt;/directory&gt;</span><br><span class="line">        &lt;includes&gt;</span><br><span class="line">            &lt;include&gt;**/*.yml&lt;/include&gt;</span><br><span class="line">            &lt;include&gt;**/*.properties&lt;/include&gt;</span><br><span class="line">            &lt;include&gt;**/*.xml&lt;/include&gt;</span><br><span class="line">        &lt;/includes&gt;</span><br><span class="line">        &lt;filtering&gt;false&lt;/filtering&gt;</span><br><span class="line">    &lt;/resource&gt;</span><br><span class="line">&lt;/resources&gt;</span><br><span class="line">&lt;/build&gt;</span><br></pre></td></tr></table></figure><h2 id="springBoot-SpringCloud整合坑"><a href="#springBoot-SpringCloud整合坑" class="headerlink" title="springBoot-SpringCloud整合坑"></a>springBoot-SpringCloud整合坑</h2><ul><li>利用SpringCloud做服务注册时，Eclipse需要自己导jar包依赖和配置版本，Idea直接可以再创建Springboot项目时鼠标点击引入，这个我就放几张图来解释：</li></ul><p><img src="springboot踩坑出坑记/springCloud1.png" alt=""><br><img src="springboot踩坑出坑记/springCloud2.png" alt=""><br><img src="springboot踩坑出坑记/springCloud3.png" alt=""></p><p>最后一个next后直接finish……</p><p>之后再pom.xml里面会看到Idea自动为你引入的依赖和 <code>spring-boot-maven-plugin</code> 插件，插件版本我建议还是稍微低一点，因为boot真的是随着版本变动改动很大，我用的是<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;plugin&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.5.9.RELEASE&lt;/version&gt;</span><br><span class="line">&lt;/plugin&gt;</span><br></pre></td></tr></table></figure></p><p>这个也是在网上搜了很久之后找到的一个版本，还有一个<code>1.4.9.RELEASE</code>也可以，之后就是看看Idea导入的<code>SpringCloud</code>依赖的版本<code>version</code>，版本错误很容易报<code>java.lang.AbstractMethodError: null</code>这个错误我找了很久，原因也是看了一个<a href="https://blog.csdn.net/kxj19980524/article/details/87860876" target="_blank" rel="noopener">大佬的博客</a>找到的，具体就是因为Idea给你的依赖是根据你选择的springboot的版本来的，一般人不会去修改，这也就是为什么eclipse不容易报错，Idea容易的原因，因为eclipse得自己找…<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;parent&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;2.0.5.RELEASE&lt;/version&gt;</span><br><span class="line">    &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;</span><br><span class="line">&lt;/parent&gt;</span><br></pre></td></tr></table></figure></p><p>我的parent的版本是<code>&lt;version&gt;2.0.5.RELEASE&lt;/version&gt;</code>，大佬的文章也提到了2.1.0和2.1.0以下的有区别，我还是建议用低的，低的差别不会太大，还挺稳……我还用过1.5.9.RELEASE…</p><ul><li>之后配置<code>eureka</code>的服务的时候Idea提供的版本也要改，这个原因是因为如果使用<code>${spring-cloud.version}</code>的话,当版本号下调到<code>2.1.0</code>以下的时候,一些组件的包还是<code>2.1.0</code>它不会跟随parent版本的下调而下调,也就是parent的版本小于组件的版本,这时候就会出问题<br>当改为<code>Finchley.RELEASE</code>的时候,组件的依赖就会跟随parent的版本下调而下调<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&lt;properties&gt;</span><br><span class="line">    &lt;java.version&gt;1.8&lt;/java.version&gt;</span><br><span class="line">    &lt;!-- 这是Idea给设的 --&gt;</span><br><span class="line">    &lt;!--&lt;spring-cloud.version&gt;Greenwich.SR1&lt;/spring-cloud.version&gt;--&gt;</span><br><span class="line">    &lt;spring-cloud.version&gt;Finchley.RELEASE&lt;/spring-cloud.version&gt;</span><br><span class="line">&lt;/properties&gt;</span><br><span class="line"></span><br><span class="line">&lt;dependencyManagement&gt;</span><br><span class="line">    &lt;dependencies&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;</span><br><span class="line">            &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt;</span><br><span class="line">            &lt;type&gt;pom&lt;/type&gt;</span><br><span class="line">            &lt;scope&gt;import&lt;/scope&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">    &lt;/dependencies&gt;</span><br><span class="line">&lt;/dependencyManagement&gt;</span><br></pre></td></tr></table></figure></li></ul><h2 id="解决静态资源跨域时的坑"><a href="#解决静态资源跨域时的坑" class="headerlink" title="解决静态资源跨域时的坑"></a>解决静态资源跨域时的坑</h2><ul><li>之前在eclipse中静态资源访问是可以通过<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">@Autowired</span><br><span class="line">private RestTemplate restTemplate;</span><br></pre></td></tr></table></figure></li></ul><p>直接装配的，之后到了Idea中报错了:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">ERROR 31473 --- [           main] o.s.b.d.LoggingFailureAnalysisReporter   : </span><br><span class="line"></span><br><span class="line">***************************</span><br><span class="line">APPLICATION FAILED TO START</span><br><span class="line">***************************</span><br><span class="line"></span><br><span class="line">Description:</span><br><span class="line"></span><br><span class="line">Field restTemplate in &apos;xxxxxx&apos;</span><br><span class="line">required a bean of type &apos;org.springframework.web.client.RestTemplate&apos; that could not be found.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Action:</span><br><span class="line"></span><br><span class="line">Consider defining a bean of type &apos;org.springframework.web.client.RestTemplate&apos; in your configuration.</span><br></pre></td></tr></table></figure></p><p>解决方法如下，大致就是先靠@Bean装配，再用…:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">@Bean</span><br><span class="line">public RestTemplate restTemplate(RestTemplateBuilder builder) &#123;</span><br><span class="line">   // Do any additional configuration here</span><br><span class="line">   return builder.build();</span><br><span class="line">&#125;</span><br><span class="line">@Autowired</span><br><span class="line">private RestTemplate restTemplate;</span><br></pre></td></tr></table></figure></p><p>之后就不报错了(针对于我的错误)</p><h2 id="我的-pom-xml-project的xml"><a href="#我的-pom-xml-project的xml" class="headerlink" title="我的 pom.xml(project的xml)"></a>我的 pom.xml(project的xml)</h2><p>我的架构</p><p><img src="springboot踩坑出坑记/jiagou.png" alt="点我"><br>圈住的地方是下方的pom.xml文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;</span><br><span class="line">         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span><br><span class="line">         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;</span><br><span class="line">    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;</span><br><span class="line">    &lt;groupId&gt;cn.yixue&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;yixue&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;</span><br><span class="line">    &lt;packaging&gt;pom&lt;/packaging&gt;</span><br><span class="line"></span><br><span class="line">    &lt;parent&gt;</span><br><span class="line">        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;</span><br><span class="line">        &lt;version&gt;2.0.5.RELEASE&lt;/version&gt;</span><br><span class="line">        &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;</span><br><span class="line">    &lt;/parent&gt;</span><br><span class="line"></span><br><span class="line">    &lt;properties&gt;</span><br><span class="line">        &lt;java.version&gt;1.8&lt;/java.version&gt;</span><br><span class="line">        &lt;lombok.version&gt;1.14.8&lt;/lombok.version&gt;</span><br><span class="line">        &lt;fastjson.version&gt;1.2.31&lt;/fastjson.version&gt;</span><br><span class="line">    &lt;/properties&gt;</span><br><span class="line"></span><br><span class="line">    &lt;dependencies&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt;</span><br><span class="line">            &lt;version&gt;1.3.2&lt;/version&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;mysql&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;</span><br><span class="line">            &lt;version&gt;5.1.46&lt;/version&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt;</span><br><span class="line">            &lt;optional&gt;true&lt;/optional&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;pagehelper-spring-boot-starter&lt;/artifactId&gt;</span><br><span class="line">            &lt;version&gt;1.2.5&lt;/version&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;</span><br><span class="line">            &lt;scope&gt;test&lt;/scope&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;lombok&lt;/artifactId&gt;</span><br><span class="line">            &lt;version&gt;$&#123;lombok.version&#125;&lt;/version&gt;</span><br><span class="line">            &lt;scope&gt;provided&lt;/scope&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;com.alibaba&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;fastjson&lt;/artifactId&gt;</span><br><span class="line">            &lt;version&gt;$&#123;fastjson.version&#125;&lt;/version&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">    &lt;/dependencies&gt;</span><br><span class="line">    &lt;build&gt;</span><br><span class="line">        &lt;plugins&gt;</span><br><span class="line">            &lt;plugin&gt;</span><br><span class="line">                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;</span><br><span class="line">                &lt;version&gt;1.5.9.RELEASE&lt;/version&gt;</span><br><span class="line">                &lt;configuration&gt;</span><br><span class="line">                    &lt;!--该配置必须--&gt;</span><br><span class="line">                    &lt;fork&gt;true&lt;/fork&gt;</span><br><span class="line">                &lt;/configuration&gt;</span><br><span class="line">            &lt;/plugin&gt;</span><br><span class="line">            &lt;plugin&gt;</span><br><span class="line">                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;</span><br><span class="line">                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;</span><br><span class="line">                &lt;configuration&gt;</span><br><span class="line">                    &lt;source&gt;1.8&lt;/source&gt;</span><br><span class="line">                    &lt;target&gt;1.8&lt;/target&gt;</span><br><span class="line">                &lt;/configuration&gt;</span><br><span class="line">            &lt;/plugin&gt;</span><br><span class="line">        &lt;/plugins&gt;</span><br><span class="line">    &lt;/build&gt;</span><br><span class="line"></span><br><span class="line">    &lt;modules&gt;</span><br><span class="line">        &lt;module&gt;yixue-commom&lt;/module&gt;</span><br><span class="line">        &lt;module&gt;yixue-admin&lt;/module&gt;</span><br><span class="line">        &lt;module&gt;yixue-video&lt;/module&gt;</span><br><span class="line">    &lt;/modules&gt;</span><br><span class="line">&lt;/project&gt;</span><br></pre></td></tr></table></figure></p><blockquote><p>这就是我移植项目遇到的一些问题，下面列一些大佬的博客，对我帮助很大，不胜感激<br>如有侵权，请联系我删除</p><ul><li><a href="https://www.cnblogs.com/skyLogin/p/9203540.html" target="_blank" rel="noopener">springboot @WebFilter过滤器的使用</a></li><li><a href="https://blog.csdn.net/kxj19980524/article/details/87860876" target="_blank" rel="noopener">java.lang.AbstractMethodError: null</a></li><li><a href="https://blog.csdn.net/kxj19980524/article/details/87860876" target="_blank" rel="noopener">不能自动装配RestTemplate  /  not found</a></li><li><a href="https://www.jianshu.com/p/836d455663da" target="_blank" rel="noopener">SpringBoot 2.0 报错: Failed to configure a DataSource: ‘url’ attribute is not specified and no embe…</a></li><li><a href="http://www.cnblogs.com/sxdcgaq8080/p/7715427.html" target="_blank" rel="noopener">在pom.xml文件中使用resources插件的小作用</a></li></ul></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;4月15到4月17我都在把毕设从eclipse重构到IDEA中，springboot最让我头疼的是它的版本问题，因为每一个版本对应的依赖包都有可能出错，这里分享一下如何成功移植用eclipse写的springboot到IDEA中，比较简单的步骤我这里不详细说了，说一下我遇到的一些很难找出问题的地方&lt;br&gt;ps:只是针对于我的项目和我个人水平，大神勿喷嘿嘿&lt;br&gt;
    
    </summary>
    
      <category term="springCloud,springboot" scheme="http://yoursite.com/categories/springCloud-springboot/"/>
    
    
      <category term="springCloud,springboot" scheme="http://yoursite.com/tags/springCloud-springboot/"/>
    
  </entry>
  
  <entry>
    <title>含有重复字符的最长子串</title>
    <link href="http://yoursite.com/2019/04/10/%E5%90%AB%E6%9C%89%E9%87%8D%E5%A4%8D%E5%AD%97%E7%AC%A6%E7%9A%84%E6%9C%80%E9%95%BF%E5%AD%90%E4%B8%B2/"/>
    <id>http://yoursite.com/2019/04/10/含有重复字符的最长子串/</id>
    <published>2019-04-10T08:25:25.000Z</published>
    <updated>2019-04-10T10:03:49.705Z</updated>
    
    <content type="html"><![CDATA[<pre><code>* 给定一个字符串，请你找出其中不含有重复字符的最长子串的长度。** 示例 1:* 输入: &quot;abcabcbb&quot;* 输出: 3* 解释: 因为无重复字符的最长子串是 &quot;abc&quot;，所以其长度为 3。</code></pre><a id="more"></a><pre><code>* &lt;p&gt;* 示例 2:* &lt;p&gt;* 输入: &quot;bbbbb&quot;* 输出: 1* 解释: 因为无重复字符的最长子串是 &quot;b&quot;，所以其长度为 1。* &lt;p&gt;* 示例 3:* &lt;p&gt;* 输入: &quot;pwwkew&quot;* 输出: 3* 解释: 因为无重复字符的最长子串是 &quot;wke&quot;，所以其长度为 3。* 请注意，你的答案必须是 子串 的长度，&quot;pwke&quot; 是一个子序列，不是子串。*/</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">public class LongestSubstring &#123;</span><br><span class="line">    public static int lengthOfLongestSubstring(String s) &#123;</span><br><span class="line">        int length = s.length();</span><br><span class="line">        if(length&lt;2) &#123;return length;&#125;</span><br><span class="line">        Set set = new HashSet();</span><br><span class="line">        int res = 0;</span><br><span class="line">        int start = 0;</span><br><span class="line">        int end = 0;</span><br><span class="line">        while (end&lt;length)&#123;</span><br><span class="line">            if(!set.contains(s.charAt(end)))&#123;</span><br><span class="line">                set.add(s.charAt(end++));</span><br><span class="line">                res = Math.max(res,set.size());</span><br><span class="line">            &#125;else&#123;</span><br><span class="line">                set.remove(s.charAt(start++));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        return res;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        int result = lengthOfLongestSubstring(&quot;abcabcbb&quot;);</span><br><span class="line">        System.out.println(result);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;* 给定一个字符串，请你找出其中不含有重复字符的最长子串的长度。
*
* 示例 1:
* 输入: &amp;quot;abcabcbb&amp;quot;
* 输出: 3
* 解释: 因为无重复字符的最长子串是 &amp;quot;abc&amp;quot;，所以其长度为 3。
&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
      <category term="算法" scheme="http://yoursite.com/categories/%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="leetcode" scheme="http://yoursite.com/tags/leetcode/"/>
    
  </entry>
  
  <entry>
    <title>慢SQL优化解决方案(看这一篇就够了)</title>
    <link href="http://yoursite.com/2019/03/25/%E6%85%A2SQL%E4%BC%98%E5%8C%96%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88-%E7%9C%8B%E8%BF%99%E4%B8%80%E7%AF%87%E5%B0%B1%E5%A4%9F%E4%BA%86/"/>
    <id>http://yoursite.com/2019/03/25/慢SQL优化解决方案-看这一篇就够了/</id>
    <published>2019-03-25T02:51:08.000Z</published>
    <updated>2019-04-17T10:57:22.569Z</updated>
    
    <content type="html"><![CDATA[<h3 id="慢SQL问题"><a href="#慢SQL问题" class="headerlink" title="慢SQL问题"></a>慢SQL问题</h3><p>导致慢 SQL 的原因：<br>在遇到慢 SQL 情况时，不能简单的把原因归结为 SQL 编写问题(虽然这是最常见的因素)<br>实际上导致慢 SQL 有很多因素，甚至包括硬件和 mysql 本身的 bug。根据出现的概率从大到小，罗列如下：<br><a id="more"></a><br>    SQL编写问题</p><pre><code>锁业务实例相互干绕对 IO/CPU 资源争用服务器硬件MYSQL BUG</code></pre><ul><li>由 SQL 编写导致的慢 SQL 优化</li></ul><blockquote><p>针对SQL编写导致的慢 SQL，优化起来还是相对比较方便的。<br>正如上一节提到的正确的使用索引能加快查询速度，那么我们在编写 SQL 时就需要注意与索引相关的规则：</p></blockquote><pre><code>1.字段类型转换导致不用索引，如字符串类型的不用引号，数字类型的用引号等，这有可能会用不到索引导致全表扫描；2.mysql 不支持函数转换，所以字段前面不能加函数，否则这将用不到索引；3.不要在字段前面加减运算；4.字符串比较长的可以考虑索引一部份减少索引文件大小，提高写入效率；5.like % 在前面用不到索引；6.根据联合索引的第二个及以后的字段单独查询用不到索引；7.不要使用 select *；8.排序请尽量使用升序 ;9.or 的查询尽量用 union 代替 （Innodb）；10.复合索引高选择性的字段排在前面；11.order by / group by 字段包括在索引当中减少排序，效率会更高。12.除了上述索引使用规则外，SQL 编写时还需要特别注意一下几点：13.尽量规避大事务的 SQL，大事务的 SQL 会影响数据库的并发性能及主从同步；14.分页语句 limit 的问题；15.删除表所有记录请用 truncate，不要用 delete；16.不让 mysql 干多余的事情，如计算；17.输写 SQL 带字段，以防止后面表变更带来的问题，性能也是比较优的 ( 涉及到数据字典解析，请自行查询资料)；18.在 Innodb上用 select count(*)，因为 Innodb 会存储统计信息；19.慎用 Oder by rand()。</code></pre><blockquote><p>分析诊断工具<br>在日常开发工作中，我们可以做一些工作达到预防慢 SQL 问题，比如在上线前预先用诊断工具对 SQL 进行分析。常用的工具有：</p></blockquote><pre><code>mysqldumpslowmysql profilemysql explain</code></pre><p>具体使用及分析方法在此就不赘述，网上有丰富的资源可以参考。</p><blockquote><p>误操作、程序 bug 时怎么办</p></blockquote><pre><code>提出这个问题显然主要是针对刚开始工作的年轻同行们……实际上误操作和程序 bug 导致数据误删或者混乱的问题并非少见但是刚入行的开发工作者会比较紧张。一个成熟的企业往往会有完善的数据管理规范和较丰富的数据恢复方案（初创公司除外）会进行数据备份和数据容灾。当你发现误操作或程序 bug 导致线上数据被误删或误改动时，一定不能慌乱，应及时与 DBA 联系第一时间进行数据恢复（严重时直接停止服务），尽可能减少影响和损失。对于重要数据（如资金）的操作，在开发时一定要反复进行测试，确保没有问题后再上线。</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;慢SQL问题&quot;&gt;&lt;a href=&quot;#慢SQL问题&quot; class=&quot;headerlink&quot; title=&quot;慢SQL问题&quot;&gt;&lt;/a&gt;慢SQL问题&lt;/h3&gt;&lt;p&gt;导致慢 SQL 的原因：&lt;br&gt;在遇到慢 SQL 情况时，不能简单的把原因归结为 SQL 编写问题(虽然这是最常见的因素)&lt;br&gt;实际上导致慢 SQL 有很多因素，甚至包括硬件和 mysql 本身的 bug。根据出现的概率从大到小，罗列如下：&lt;br&gt;
    
    </summary>
    
    
      <category term="SQL" scheme="http://yoursite.com/tags/SQL/"/>
    
  </entry>
  
  <entry>
    <title>字符移位问题</title>
    <link href="http://yoursite.com/2019/03/20/%E5%AD%97%E7%AC%A6%E7%A7%BB%E4%BD%8D%E9%97%AE%E9%A2%98/"/>
    <id>http://yoursite.com/2019/03/20/字符移位问题/</id>
    <published>2019-03-20T09:12:41.000Z</published>
    <updated>2019-04-10T08:36:23.749Z</updated>
    
    <content type="html"><![CDATA[<p>有一个由小写字母组成的字符串 S，和一个整数数组 shifts。我们将字母表中的下一个字母称为原字母的 移位（由于字母表是环绕的， ‘z’ 将会变成 ‘a’）。例如·，shift(‘a’) = ‘b’， shift(‘t’) = ‘u’,， 以及 shift(‘z’) = ‘a’。对于每个 shifts[i] = x ， 我们会将 S 中的前 i+1 个字母移位 x 次。返回将所有这些移位都应用到 S 后最终得到的字符串。<br><a id="more"></a></p><h3 id="字符移位问题-leetcode-843"><a href="#字符移位问题-leetcode-843" class="headerlink" title="字符移位问题 leetcode 843"></a>字符移位问题 leetcode 843</h3><pre><code>/*** 字符移位问题 leetcode 843* 有一个由小写字母组成的字符串 S，和一个整数数组 shifts。* 我们将字母表中的下一个字母称为原字母的 移位（由于字母表是环绕的， &apos;z&apos; 将会变成 &apos;a&apos;）。* 例如·，shift(&apos;a&apos;) = &apos;b&apos;， shift(&apos;t&apos;) = &apos;u&apos;,， 以及 shift(&apos;z&apos;) = &apos;a&apos;。* 对于每个 shifts[i] = x ， 我们会将 S 中的前 i+1 个字母移位 x 次。* 返回将所有这些移位都应用到 S 后最终得到的字符串。** 示例：* 输入：S = &quot;abc&quot;, shifts = [3,5,9]* 输出：&quot;rpl&quot;* 解释：* 我们以 &quot;abc&quot; 开始。* 将 S 中的第 1 个字母移位 3 次后，我们得到 &quot;dbc&quot;。* 再将 S 中的前 2 个字母移位 5 次后，我们得到 &quot;igc&quot;。* 最后将 S 中的这 3 个字母移位 9 次后，我们得到答案 &quot;rpl&quot;。*/</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line">public class shiftingLetters &#123;</span><br><span class="line">    /**</span><br><span class="line">     * 方法一：不推荐，但好理解</span><br><span class="line">     * @author yiming.liang</span><br><span class="line">     * @date 2019/3/20 15:33</span><br><span class="line">     * @param [S, shifts]</span><br><span class="line">     * @return java.lang.String</span><br><span class="line">     */</span><br><span class="line">        public static String shiftingLetter(String S, int[] shifts) &#123;</span><br><span class="line">            //目的为了拼字符串的</span><br><span class="line">            StringBuffer sb = new StringBuffer();</span><br><span class="line">            char c = 0;</span><br><span class="line">            for(int i = shifts.length-2;i&gt;=0;i--)&#123;</span><br><span class="line">                //从后往前算应该向后走几步,因为题目中说第二个走，第一个也走，第三个走，前两个也走</span><br><span class="line">                //所以最后一个走的是最少的，只走一步，而第一个走的最多，是后几个步数的和</span><br><span class="line">                //这样就比较好理解，我们直接从倒数第二个字母开始，将他和最后一人走的加起来，算出倒数第二个字母走的步数</span><br><span class="line">                //之后依次累加即可</span><br><span class="line">                shifts[i] += shifts[i+1]%26;</span><br><span class="line">            &#125;</span><br><span class="line">            for (int i = 0; i &lt; S.length(); i++) &#123;</span><br><span class="line">//                c = (char)(c.charAt(i) - &apos;a&apos; + shift) % 26 + &apos;a&apos;);</span><br><span class="line">                //这里分情况，上面那个是最好的方式但难理解，下面那个是好理解但麻烦</span><br><span class="line">                //下面这边分两种情况，第一钟是字母向后走但不超过z 直接加即可</span><br><span class="line">                c = (char)(S.charAt(i) + shifts[i]%26);</span><br><span class="line">                //如果超了z即122，这里拿一个栗子来说明,用例中&quot;ruu&quot;，&#123;26,9,17&#125;;</span><br><span class="line">                //u要向后走17步，而u的ascii码为117，走17步明显超过了z则判断是否大于122</span><br><span class="line">                //如果大于122，则算出大了多少，17+117-122 = 12则我们从u开始还要向后走5步到z</span><br><span class="line">                //再返回去走12步，这时我们是从z开始走的，则a也要被算在内，而我们后面的+&apos;a&apos;则代表着从a开始走</span><br><span class="line">                //显然a也被算在这12步内了，所以要-1再+&apos;a&apos;</span><br><span class="line">                //over</span><br><span class="line">                if(c&gt;122)&#123;</span><br><span class="line">                    c = (char) ((c-122)-1 + &apos;a&apos;);</span><br><span class="line">                    sb.append(c);</span><br><span class="line">                &#125;else&#123;</span><br><span class="line">                    sb.append(c);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            return sb.toString();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        /**</span><br><span class="line">         * 方法二:推荐</span><br><span class="line">         * @author yiming.liang</span><br><span class="line">         * @date 2019/3/20 16:45</span><br><span class="line">         * @param [S, shifts]</span><br><span class="line">         * @return java.lang.String</span><br><span class="line">         */</span><br><span class="line">        public String shiftingLetter2(String S, int[] shifts) &#123;</span><br><span class="line">            char[] arr = S.toCharArray();</span><br><span class="line">            int shift = 0;</span><br><span class="line">            for (int i = arr.length - 1; i &gt;= 0; i--) &#123;</span><br><span class="line">                shift = (shift + shifts[i]) % 26;</span><br><span class="line">                arr[i] = (char)((arr[i] - &apos;a&apos; + shift) % 26 + &apos;a&apos;);</span><br><span class="line">            &#125;</span><br><span class="line">            return new String(arr);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">//            char i = &apos;a&apos;+1;</span><br><span class="line">        int[] shifts = &#123;26,9,17&#125;;</span><br><span class="line">        String str = shiftingLetter(&quot;ruu&quot;,shifts);</span><br><span class="line">        System.out.println(str);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;有一个由小写字母组成的字符串 S，和一个整数数组 shifts。我们将字母表中的下一个字母称为原字母的 移位（由于字母表是环绕的， ‘z’ 将会变成 ‘a’）。例如·，shift(‘a’) = ‘b’， shift(‘t’) = ‘u’,， 以及 shift(‘z’) = ‘a’。对于每个 shifts[i] = x ， 我们会将 S 中的前 i+1 个字母移位 x 次。返回将所有这些移位都应用到 S 后最终得到的字符串。&lt;br&gt;
    
    </summary>
    
      <category term="算法" scheme="http://yoursite.com/categories/%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="leetcode" scheme="http://yoursite.com/tags/leetcode/"/>
    
  </entry>
  
  <entry>
    <title>leetcode 1013:总持续时间可被60整除的歌曲</title>
    <link href="http://yoursite.com/2019/03/20/leetcode-1013-%E6%80%BB%E6%8C%81%E7%BB%AD%E6%97%B6%E9%97%B4%E5%8F%AF%E8%A2%AB-60-%E6%95%B4%E9%99%A4%E7%9A%84%E6%AD%8C%E6%9B%B2/"/>
    <id>http://yoursite.com/2019/03/20/leetcode-1013-总持续时间可被-60-整除的歌曲/</id>
    <published>2019-03-20T07:03:42.000Z</published>
    <updated>2019-03-20T07:14:34.504Z</updated>
    
    <content type="html"><![CDATA[<h3 id="leetcode-1013-总持续时间可被-60-整除的歌曲"><a href="#leetcode-1013-总持续时间可被-60-整除的歌曲" class="headerlink" title="leetcode 1013:总持续时间可被 60 整除的歌曲"></a>leetcode 1013:总持续时间可被 60 整除的歌曲</h3><blockquote><p>在歌曲列表中，第 i 首歌曲的持续时间为 time[i] 秒。<br>返回其总持续时间（以秒为单位）可被 60 整除的歌曲对的数量。形式上，我们希望索引的数字  i &lt; j 且有 (time[i] + time[j]) % 60 == 0。</p></blockquote><pre><code>示例 1：输入：[30,20,150,100,40]输出：3解释：这三对的总持续时间可被 60 整数：(time[0] = 30, time[2] = 150): 总持续时间 180(time[1] = 20, time[3] = 100): 总持续时间 120(time[1] = 20, time[4] = 40): 总持续时间 60示例 2：输入：[60,60,60]输出：3解释：所有三对的总持续时间都是 120，可以被 60 整数。</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">方法1：时间复杂度O(n^2)，效率奇低</span><br><span class="line">class Solution &#123;</span><br><span class="line">    public int numPairsDivisibleBy60(int[] time) &#123;</span><br><span class="line">        int resutl = 0;</span><br><span class="line">        for(int i = 0;i&lt;time.length-1;i++)&#123;</span><br><span class="line">            for (int j = i+1; j &lt; time.length; j++) &#123;</span><br><span class="line">                if(time[i]+time[j]%60==0)&#123;</span><br><span class="line">                    result++;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">方法2：</span><br><span class="line">    利用数组，将每个数对60取模后的值当作新数组的下标，并记录次数</span><br><span class="line">    接着遇到连续多个都能整出60的数，则此时 arr[0]的值应该会++多次</span><br><span class="line">    若arr[0]=3 即有3个60，他们两两组合则可以组合的数量为(n(n-1))/2 result = (3*2)/2 = 3</span><br><span class="line">    同理，取mode后的值为30也是特殊情况，则组合的方法和0的一样，接着下面写就可以了</span><br><span class="line">    排除了特殊情况后，正常情况就是20  40,   10   50之类的相加为60的数，这些数2 2 组合直接乘就可以了</span><br><span class="line">    </span><br><span class="line">class Solution &#123;</span><br><span class="line">    public int numPairsDivisibleBy60(int[] time) &#123;</span><br><span class="line">        int result = 0;</span><br><span class="line">        int[] res = new int[60];</span><br><span class="line">        for(int i:time)&#123;</span><br><span class="line">            res[i%60]++;</span><br><span class="line">        &#125;</span><br><span class="line">        result += (res[0] * (res[0]-1))/2;</span><br><span class="line">        result += (res[30] * (res[30]-1))/2;</span><br><span class="line">        //正常情况，相加为60证明一定能被60整除</span><br><span class="line">        for(int i = 1;i&lt;30;i++)&#123;</span><br><span class="line">            result += (res[i] * res[60-i]);</span><br><span class="line">        &#125;</span><br><span class="line">        return result;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;leetcode-1013-总持续时间可被-60-整除的歌曲&quot;&gt;&lt;a href=&quot;#leetcode-1013-总持续时间可被-60-整除的歌曲&quot; class=&quot;headerlink&quot; title=&quot;leetcode 1013:总持续时间可被 60 整除的歌曲&quot;&gt;
      
    
    </summary>
    
      <category term="JAVA" scheme="http://yoursite.com/categories/JAVA/"/>
    
    
      <category term="Leetcode" scheme="http://yoursite.com/tags/Leetcode/"/>
    
  </entry>
  
  <entry>
    <title>Kafka如何利用Zookeeper做负载均衡</title>
    <link href="http://yoursite.com/2019/03/20/Kafka%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8Zookeeper%E5%81%9A%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"/>
    <id>http://yoursite.com/2019/03/20/Kafka如何利用Zookeeper做负载均衡/</id>
    <published>2019-03-20T03:01:08.000Z</published>
    <updated>2019-03-20T03:02:07.958Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Kafka与Zookeeper"><a href="#Kafka与Zookeeper" class="headerlink" title="Kafka与Zookeeper"></a>Kafka与Zookeeper</h3><ul><li><p>Kafka如何利用zookeeper做负载均衡</p><pre><code>Kafka使用zk的分布式协调服务，将生产者，消费者，消息储存（broker，用于存储信息，消息读写等）结合在一起。同时借助zk，kafka能够将生产者，消费者和broker在内的所有组件在无状态的条件下建立起生产者和消费者的订阅关系，实现生产者的负载均衡。</code></pre><ul><li><p>broker在zk中注册</p><p>  kafka的每个broker（相当于一个节点，相当于一个机器）在启动时，都会在zk中注册，告诉zk其brokerid，在整个的集群中，<code>broker.id/brokers/ids</code>，当节点失效时，zk就会删除该节点，就很方便的监控整个集群broker的变化，及时调整负载均衡。</p></li><li><p>topic在zk中注册</p><p>  在kafka中可以定义很多个topic，每个topic又被分为很多个分区。一般情况下，每个分区独立在存在一个broker上，所有的这些topic和broker的对应关系都有zk进行维护</p></li><li><p>consumer(消费者)在zk中注册</p><ul><li><p>注册新的消费者，当有新的消费者注册到zk中，zk会创建专用的节点来保存相关信息，路径<code>ls /consumers/{group_id}/  [ids,owners,offset]</code>，Ids:记录该消费分组有几个正在消费的消费者，Owmners：记录该消费分组消费的topic信息，Offset：记录topic每个分区中的每个offset</p></li><li><p>监听消费者分组中消费者的变化 ,监听/consumers/{group_id}/ids的子节点的变化，一旦发现消费者新增或者减少及时调整消费者的负载均衡。</p></li></ul></li></ul><hr><p>  转载<br>  作者：SmartBrain<br>  原文：<a href="https://blog.csdn.net/Peter_Changyb/article/details/81562855" target="_blank" rel="noopener">https://blog.csdn.net/Peter_Changyb/article/details/81562855</a> </p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Kafka与Zookeeper&quot;&gt;&lt;a href=&quot;#Kafka与Zookeeper&quot; class=&quot;headerlink&quot; title=&quot;Kafka与Zookeeper&quot;&gt;&lt;/a&gt;Kafka与Zookeeper&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Kafka如何利用
      
    
    </summary>
    
      <category term="kafka" scheme="http://yoursite.com/categories/kafka/"/>
    
    
      <category term="kafka" scheme="http://yoursite.com/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>maven之pom.xml中的元素解析</title>
    <link href="http://yoursite.com/2019/03/19/maven%E4%B9%8Bpom-xml%E4%B8%AD%E7%9A%84%E5%85%83%E7%B4%A0%E8%A7%A3%E6%9E%90/"/>
    <id>http://yoursite.com/2019/03/19/maven之pom-xml中的元素解析/</id>
    <published>2019-03-19T12:14:44.000Z</published>
    <updated>2019-04-12T06:03:32.436Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Maven-pom-xml-中元素解析"><a href="#Maven-pom-xml-中元素解析" class="headerlink" title="Maven-pom.xml-中元素解析"></a>Maven-pom.xml-中元素解析</h2><h3 id="modules"><a href="#modules" class="headerlink" title="modules"></a>modules</h3><pre><code>模块用处：项目规模比较大，模块较为复杂，目的是为了聚合，一次性构建全部模块</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">代码：</span><br><span class="line">&lt;modules&gt;</span><br><span class="line">　　　 &lt;!-- 模块都写在此处 --&gt;</span><br><span class="line">      &lt;module&gt;admin-register&lt;/module&gt;</span><br><span class="line">      &lt;module&gt;admin-login&lt;/module&gt;</span><br><span class="line">&lt;/modules&gt;</span><br></pre></td></tr></table></figure><h3 id="dependencyManagement"><a href="#dependencyManagement" class="headerlink" title="dependencyManagement"></a>dependencyManagement</h3><pre><code>依赖管理用处：管理maven依赖</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">代码：</span><br><span class="line">&lt;dependencies&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;com.yixue.sms&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;sms-dubbo-api&lt;/artifactId&gt;</span><br><span class="line">        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">&lt;/dependencies&gt;</span><br></pre></td></tr></table></figure><h3 id="parent"><a href="#parent" class="headerlink" title="parent"></a>parent</h3><pre><code>继承用处：类似与java中的继承，如果每个子模块都用了相同的依赖包，则配置父模块，子模块继承父模块则代表继承了父模块的依赖包</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">代码：</span><br><span class="line">父：</span><br><span class="line"></span><br><span class="line">&lt;modules&gt;</span><br><span class="line">　　　 &lt;!-- 模块都写在此处 --&gt;</span><br><span class="line">      &lt;module&gt;admin-register&lt;/module&gt;</span><br><span class="line">      &lt;module&gt;admin-login&lt;/module&gt;</span><br><span class="line">&lt;/modules&gt;</span><br><span class="line"></span><br><span class="line">&lt;dependencies&gt; &lt;!-- 配置共有依赖 --&gt;</span><br><span class="line">    &lt;!-- spring 依赖 --&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;org.springframework&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;spring-core&lt;/artifactId&gt;</span><br><span class="line">        &lt;version&gt;4.0.2.RELEASE&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;org.springframework&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;spring-beans&lt;/artifactId&gt;</span><br><span class="line">        &lt;version&gt;4.0.2.RELEASE&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;org.springframework&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;spring-context&lt;/artifactId&gt;</span><br><span class="line">        &lt;version&gt;4.0.2.RELEASE&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;org.springframework&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt;</span><br><span class="line">        &lt;version&gt;4.0.2.RELEASE&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">&lt;/dependencies&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">子：</span><br><span class="line">&lt;parent&gt;</span><br><span class="line">    &lt;groupId&gt;com.admin.user&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;admin-login&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;</span><br><span class="line">    &lt;relativePath&gt;../pom.xml&lt;/relativePath&gt; </span><br><span class="line">    &lt;!-- 与不配置一样，默认就是寻找上级目录下得pom.xml --&gt;</span><br><span class="line">&lt;/parent&gt;</span><br><span class="line">&lt;!-- 配置自己独有依赖 --&gt;</span><br><span class="line">&lt;dependencies&gt;   </span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;javax.mail&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;mail&lt;/artifactId&gt;</span><br><span class="line">        &lt;version&gt;1.4.3&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;com.icegreen&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;greenmail&lt;/artifactId&gt;</span><br><span class="line">        &lt;version&gt;1.4.1&lt;/version&gt;</span><br><span class="line">        &lt;scope&gt;test&lt;/scope&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">&lt;/dependencies&gt;</span><br></pre></td></tr></table></figure><pre><code>假设将来需要添加一个新的子模块admin-util，该模块只是提供一些简单的帮助工具，不需要依赖spring那么我们可以用dependencyManagement既能让子模块继承到父模块的依赖配置，又能保证子模块依赖使用的灵活性在dependencyManagement元素下得依赖声明不会引入实际的依赖，不过它能够约束dependencies下的依赖使用父POM使用dependencyManagement能够统一项目范围中依赖的版本当依赖版本在父POM中声明后，子模块在使用依赖的时候就无须声明版本，也就不会发生多个子模块使用版本不一致的情况，帮助降低依赖冲突的几率</code></pre><h3 id="properties"><a href="#properties" class="headerlink" title="properties"></a>properties</h3><pre><code>自定义一个或者多个Maven属性，然后再POM的其他地方使用${属性名}的方式引用该属性作用：消除重复，统一管理</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">用法</span><br><span class="line">&lt;properties&gt;</span><br><span class="line">    &lt;!-- 定义 spring版本号 --&gt;</span><br><span class="line">    &lt;spring.version&gt;4.0.2.RELEASE&lt;/spring.version&gt;</span><br><span class="line">    &lt;junit.version&gt;4.7&lt;/junit.version&gt;</span><br><span class="line">&lt;/properties&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">这里我记录了一些pom的属性：</span><br><span class="line"></span><br><span class="line">用户可以使用该类属性引用POM文件中对应元素的值。如：</span><br><span class="line"></span><br><span class="line">       $&#123;project.artifactId&#125;就对应了&lt;project&gt; &lt;artifactId&gt;元素的值，常用的POM属性包括：</span><br><span class="line"></span><br><span class="line">　　　　$&#123;project.build.sourceDirectory&#125;:项目的主源码目录，默认为src/main/java/</span><br><span class="line"></span><br><span class="line">　　　　$&#123;project.build.testSourceDirectory&#125;:项目的测试源码目录，默认为src/test/java/</span><br><span class="line"></span><br><span class="line">       $&#123;project.build.sourceEncoding&#125;表示主源码的编码格式;</span><br><span class="line"></span><br><span class="line">　　　　$&#123;project.build.directory&#125; ： 项目构建输出目录，默认为target/</span><br><span class="line"></span><br><span class="line">　　　　$&#123;project.outputDirectory&#125; : 项目主代码编译输出目录，默认为target/classes/</span><br><span class="line"></span><br><span class="line">　　　　$&#123;project.testOutputDirectory&#125;：项目测试主代码输出目录，默认为target/testclasses/</span><br><span class="line"></span><br><span class="line">　　　　$&#123;project.groupId&#125;：项目的groupId</span><br><span class="line"></span><br><span class="line">　　　　$&#123;project.artifactId&#125;：项目的artifactId</span><br><span class="line"></span><br><span class="line">　　　　$&#123;project.version&#125;：项目的version,与$&#123;version&#125; 等价</span><br><span class="line"></span><br><span class="line">　　　　$&#123;project.build.finalName&#125;：项目打包输出文件的名称，默认为$&#123;project.artifactId&#125;-$&#123;project.version&#125;</span><br></pre></td></tr></table></figure><h3 id="Exclusions"><a href="#Exclusions" class="headerlink" title="Exclusions"></a>Exclusions</h3><pre><code>排除依赖用法：来排除一些不需要同时下载的依赖jar举例：B项目中需要导入A项目的Maven依赖，通过依赖传递，会将A中的Jar包传递进来，如果B中不需要A中的某个jar包就可以使用exclusions标签</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">用法：</span><br><span class="line">&lt;dependency&gt; </span><br><span class="line">    &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; </span><br><span class="line">    &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; </span><br><span class="line">    &lt;exclusions&gt; </span><br><span class="line">        &lt;exclusion&gt; </span><br><span class="line">            &lt;artifactId&gt;commons-logging&lt;/artifactId&gt; </span><br><span class="line">            &lt;groupId&gt;commons-logging&lt;/groupId&gt; </span><br><span class="line">        &lt;/exclusion&gt; </span><br><span class="line">    &lt;/exclusions&gt; </span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><h3 id="环境变量属性"><a href="#环境变量属性" class="headerlink" title="环境变量属性"></a>环境变量属性</h3><pre><code>所有环境变量属性都可以使用以env. 开头的Maven属性引用，如${env.JAVA_HOME}指代了JAVA_HOME环境变量的的值beta:软件的验收测试如果配置了&lt;env&gt;beta&lt;/env&gt;${env} = beta</code></pre><h3 id="内置属性"><a href="#内置属性" class="headerlink" title="内置属性"></a>内置属性</h3><pre><code>(Maven预定义,用户可以直接使用)${basedir}表示项目根目录,即包含pom.xml文件的目录;${version}表示项目版本;${project.basedir}同${basedir};${project.baseUri}表示项目文件地址;${maven.build.timestamp}表示项目构件开始时间;${maven.build.timestamp.format}表示属性${maven.build.timestamp}的展示格式,默认值为yyyyMMdd-HHmm,可自定义其格式,其类型可参考java.text.SimpleDateFormat。用法如下：</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;properties&gt;</span><br><span class="line">&lt;maven.build.timestamp.format&gt;yyyy-MM-dd HH:mm:ss&lt;/maven.build.timestamp.format&gt;</span><br><span class="line">&lt;/properties&gt;</span><br></pre></td></tr></table></figure><h3 id="build"><a href="#build" class="headerlink" title="build"></a>build</h3><pre><code>在Maven的pom.xml文件中，存在如下两种&lt;build&gt;：（1）全局配置（project build）        针对整个项目的所有情况都有效（2）配置（profile build）        针对不同的profile配置共用的基本build元素:defaultGoal，执行构建时默认的goal或phase，如jar:jar或者package等directory，构建的结果所在的路径，默认为${basedir}/target目录finalName，构建的最终结果的名字，该名字可能在其他plugin中被改变&lt;build&gt;    &lt;filters&gt;        &lt;filter&gt;../config/filters-${env}.properties&lt;/filter&gt;    &lt;/filters&gt;    &lt;resources&gt;        &lt;resource&gt;            &lt;directory&gt;src/main/resources/&lt;/directory&gt;            &lt;excludes&gt;                &lt;exclude&gt;test/*&lt;/exclude&gt;                &lt;exclude&gt;beta/*&lt;/exclude&gt;                &lt;exclude&gt;online/*&lt;/exclude&gt;            &lt;/excludes&gt;            &lt;!-- 是否使用过滤器 --&gt;            &lt;filtering&gt;true&lt;/filtering&gt;        &lt;/resource&gt;        &lt;resource&gt;            &lt;directory&gt;src/main/resources/${profiles.active}&lt;/directory&gt;        &lt;/resource&gt;    &lt;/resources&gt;&lt;/build&gt;resources，build过程中涉及的资源文件targetPath，资源文件的目标路径filtering，构建过程中是否对资源进行过滤，默认falsedirectory，资源文件的路径，默认位于${basedir}/src/main/resources/目录下includes，一组文件名的匹配模式，被匹配的资源文件将被构建过程处理excludes，一组文件名的匹配模式，被匹配的资源文件将被构建过程忽略。同时被includes和excludes匹配的资源文件，将被忽略。filters，给出对资源文件进行过滤的属性文件的路径，默认位于${basedir}/src/main/filters/目录下。属性文件中定义若干键值对。在构建过程中，对于资源文件中出现的变量（键），将使用属性文件中该键对应的值替换。testResources，test过程中涉及的资源文件，默认位于${basedir}/src/test/resources/目录下。这里的资源文件不会被构建到目标构件中</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Maven-pom-xml-中元素解析&quot;&gt;&lt;a href=&quot;#Maven-pom-xml-中元素解析&quot; class=&quot;headerlink&quot; title=&quot;Maven-pom.xml-中元素解析&quot;&gt;&lt;/a&gt;Maven-pom.xml-中元素解析&lt;/h2&gt;&lt;h3 i
      
    
    </summary>
    
      <category term="maven" scheme="http://yoursite.com/categories/maven/"/>
    
    
      <category term="maven" scheme="http://yoursite.com/tags/maven/"/>
    
  </entry>
  
  <entry>
    <title>Leetcode 177 第N高的薪水</title>
    <link href="http://yoursite.com/2019/02/22/Leetcode-177-%E7%AC%ACN%E9%AB%98%E7%9A%84%E8%96%AA%E6%B0%B4/"/>
    <id>http://yoursite.com/2019/02/22/Leetcode-177-第N高的薪水/</id>
    <published>2019-02-22T13:35:20.000Z</published>
    <updated>2019-02-22T13:45:28.982Z</updated>
    
    <content type="html"><![CDATA[<h2 id="编写一个-SQL-查询，获取-Employee-表中第-n-高的薪水（Salary）。"><a href="#编写一个-SQL-查询，获取-Employee-表中第-n-高的薪水（Salary）。" class="headerlink" title="编写一个 SQL 查询，获取 Employee 表中第 n 高的薪水（Salary）。"></a>编写一个 SQL 查询，获取 Employee 表中第 n 高的薪水（Salary）。</h2><ul><li><p>测试数据</p><pre><code>+----+--------+| Id | Salary |+----+--------+| 1  | 100    || 2  | 200    || 3  | 300    |+----+--------+</code></pre></li><li><p>例如上述 Employee 表，n = 2 时，应返回第二高的薪水 200。如果不存在第 n 高的薪水，那么查询应返回 null。</p><pre><code>+------------------------+| getNthHighestSalary(2) |+------------------------+| 200                    |+------------------------+</code></pre></li><li><p>首先拿到题直接思考使用分析函数了,是使用<code>row_number()</code>还是<code>dense_rank()</code></p><ul><li><p>row_number() over()是无论值是否相同值始终递增</p><pre><code>100 1200 2200 3300 4</code></pre></li><li><p>dense_rank() over()是重复的值显示的排名都相同，但其后的值跟着上一个值递增，不跳跃</p><pre><code>100 1200 2200 2300 3</code></pre></li><li><p>rank() over()则是重复值的排名相同，但其后的值从重复行数开始递增，跳跃式</p><pre><code>100 1200 2200 2300 4</code></pre></li></ul></li><li><p>题解</p><pre><code>CREATE FUNCTION getNthHighestSalary(N IN NUMBER) RETURN NUMBER ISresult NUMBER;BEGIN    /* Write your PL/SQL query statement below */    SELECT a.salary into result from         (            select dense_rank() over(order by Salary desc) as rank,Salary from Employee        )a    where  a.rank = N;    RETURN result;END;</code></pre></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;编写一个-SQL-查询，获取-Employee-表中第-n-高的薪水（Salary）。&quot;&gt;&lt;a href=&quot;#编写一个-SQL-查询，获取-Employee-表中第-n-高的薪水（Salary）。&quot; class=&quot;headerlink&quot; title=&quot;编写一个 S
      
    
    </summary>
    
      <category term="数据库" scheme="http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="Oracle" scheme="http://yoursite.com/tags/Oracle/"/>
    
  </entry>
  
  <entry>
    <title>Spark访问数据库的几种方法</title>
    <link href="http://yoursite.com/2019/02/08/Spark%E8%AE%BF%E9%97%AE%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E6%B3%95/"/>
    <id>http://yoursite.com/2019/02/08/Spark访问数据库的几种方法/</id>
    <published>2019-02-08T15:41:54.000Z</published>
    <updated>2019-03-27T07:51:06.199Z</updated>
    
    <content type="html"><![CDATA[<p>这篇文章涵盖了spark与常用关系型数据库交互的所有内容(oracle,sqlserver与mysql类似这里就不详细说明了)，这也是我项目中用到最常用的几种，应该可以帮助大家快速开发项目<br><a id="more"></a></p><h2 id="Spark访问Hive数据库"><a href="#Spark访问Hive数据库" class="headerlink" title="Spark访问Hive数据库"></a>Spark访问Hive数据库</h2><h3 id="spark访问hive数据库有两种方式"><a href="#spark访问hive数据库有两种方式" class="headerlink" title="spark访问hive数据库有两种方式"></a>spark访问hive数据库有两种方式</h3><ol><li><p>第一种是原始的jdbc访问hive数据库</p><pre><code>import java.sql.DriverManagerobject HiveJDBC {    def main(args: Array[String]): Unit = {        //1. 利用反射机制获取数据库驱动类        val driver = &quot;org.apache.hive.jdbc.HiveDriver&quot;        Class.forName(driver)        //2. 声明hive数据库的url,username,password        val (url,username,password) = (&quot;jdbc:hive2://master:10000&quot;,&quot;spark&quot;,&quot;&quot;)        //2.1 获取数据库连接对象         val connection = DriverManager.getConnection(url,username,password)        //2.2 编写sql语句        val sql = &quot;select count(*) as count from sogou.sogou500w_ext&quot;        //3. 执行sql语句        val statement = connection.prepareStatement(sql)        //4. 处理结果集        val result = statement.executeQuery()        //4. 循环打印结果        while(result.next()){        println(s&quot;${result.getString(&quot;mycount&quot;)}&quot;)        }        //5. 关闭连接        result.close()        statement.close()        connection.close()    }}</code></pre></li><li><p>第二种是通过spark自带的访问数据库的方法，在配置sparkSession时引入<code>enableHiveSupport()</code>支持hive的访问</p><pre><code>import org.apache.log4j.{Level, Logger}import org.apache.spark.sql.SparkSessionobject ReadHive {//隐藏打印的配置信息Logger.getLogger(&quot;org&quot;).setLevel(Level.ERROR)def main(args: Array[String]): Unit = {    val spark = SparkSession.builder()    .appName(&quot;Spark Hive Demo&quot;)    .master(&quot;local&quot;)    .enableHiveSupport()//支持hive，这个是关键，没有不行！    .getOrCreate()    //spark.sparkContext.addJar(&quot;/home/ymliang/ReadHive.jar&quot;)    //利用sparksql访问hive数据库，本质是编写sql语句    spark.sql(&quot;use sogou&quot;)    //show-&gt;spark的action算子，打印结果，默认20行数据    spark.sql(&quot;select * from sogou.sogou500w_ext&quot;).show()    spark.stop()}}</code></pre></li></ol><h2 id="Spark访问MySql数据库"><a href="#Spark访问MySql数据库" class="headerlink" title="Spark访问MySql数据库"></a>Spark访问MySql数据库</h2><h3 id="spark访问mysql数据库的三种方式"><a href="#spark访问mysql数据库的三种方式" class="headerlink" title="spark访问mysql数据库的三种方式"></a>spark访问mysql数据库的三种方式</h3><ol><li><p>用jdbc方式访问mysql数据库</p><pre><code>/*** 读取数据库中的数据* 备注：* 1、将jdbc驱动拷贝到$SPARK_HOME/conf目录下，是最简单的做法；* 2、明白每一个参数的意思，一个参数不对整个结果出不来；* 3、从数据库从读大量的数据进行分析，不推荐；读取少量的数据是可以接受的，也是常见的做法。*/object MySqlJDBC {    def main(args: Array[String]): Unit = {        val spark = SparkSession.builder()        .master(&quot;local&quot;)        .appName(s&quot;${this.getClass.getCanonicalName}&quot;)        .getOrCreate()        /**        * 配置jdbc参数        * url : mysql的url        * driver : mysql的数据库驱动类        * dbtable : 表名        * user : 用户名        * password : 密码        * load() : 加载        */        val jdbcDF = spark.read.format(&quot;jdbc&quot;)        .option(&quot;url&quot;,&quot;jdbc:mysql://master:3306/spark&quot;)        .option(&quot;driver&quot;,&quot;com.mysql.jdbc.Driver&quot;)        .option(&quot;dbtable&quot;,&quot;student&quot;)        .option(&quot;user&quot;,&quot;spark&quot;)        .option(&quot;password&quot;,&quot;spark&quot;)        .load()        //将读出的数据库信息创建临时表，常用方法是createOrReplaceTempView(创建,如果存在则重新创建视图)        jdbcDF.createTempView(&quot;tmp&quot;)        //格式化打印表内容        spark.sql(&quot;select * from tmp&quot;).show()        //打印列的Schema属性        jdbcDF.printSchema    }}</code></pre></li><li><p>创建一个数据库工具类(使用事务和批处理，提高性能)</p><ul><li>首先为什么要使用批处理？</li><li>批处理时：数据累积到一定数量，再一次性提交到数据库，减少了与数据库的交互次数，所以效率会大大提高</li><li><p>事务：事务指逻辑上的一组操作，组成这组操作的各个单元，要不全部成功，要不全部不成功，默认是关闭事务的。</p><pre><code>import java.sql.{Connection, DriverManager, PreparedStatement, ResultSet}/***  既用事务，也用批处理；（建议在处理大批量的数据时，同时使用批处理和事务）*/object MySqlUtils {/*** 获取一个数据库连接对象** @return Connection*/def getConnect(): Connection = {    var conn: Connection = null    var psts: PreparedStatement = null    try {    Class.forName(&quot;com.mysql.jdbc.Driver&quot;)    conn = DriverManager.getConnection(&quot;jdbc:mysql://master:3306/spark&quot;, &quot;spark&quot;, &quot;spark&quot;)    conn.setAutoCommit(false)//将自动提交关闭    } catch {    case e:Exception =&gt; e.printStackTrace()    }    conn}/**    * 关闭连接 con,psts,res Object    *///Connection conn, ResultSet rs, Statement stdef closeRes(con: Connection, rs: ResultSet, psts: PreparedStatement): Unit = {    if (con != null) {        try {            con.close()        } catch {            case e: Exception =&gt; e.printStackTrace()        }    }    if (rs != null) {        try {            rs.close()        } catch {            case e: Exception =&gt; e.printStackTrace()        }    }    if (psts != null) {        try {            psts.close()        } catch {            case e: Exception =&gt; e.printStackTrace()        }    }}}</code></pre></li><li><p>具体使用这个工具类时，调用方法获取连接关闭链接即可，这里举一个之前做的小demo</p><pre><code>import java.sql.{Connection, PreparedStatement}import org.apache.log4j.{Level, Logger}import org.apache.spark.{SparkConf, SparkContext}object LogTest1 {//隐藏打印信息Logger.getLogger(&quot;org&quot;).setLevel(Level.ERROR)def main(args: Array[String]): Unit = {    val conf = new SparkConf()    .setAppName(this.getClass.getCanonicalName)    .setMaster(&quot;local&quot;)    val sc = new SparkContext(conf)    //读文件    val file = sc.textFile(&quot;hdfs://master:9000/sparkTest01.log&quot;)    //处理文件    //数据文件大致内容如下:    //192.168.88.1 - - [30/Jul/2017:12:53:43 +0800] &quot;GET /MyDemoWeb/ HTTP/1.1&quot; 200 259    //192.168.88.1 - - [30/Jul/2017:12:53:43 +0800] &quot;GET /MyDemoWeb/head.jsp HTTP/1.1&quot; 200 713    //192.168.88.1 - - [30/Jul/2017:12:53:43 +0800] &quot;GET /MyDemoWeb/body.jsp HTTP/1.1&quot; 200 240    //192.168.88.1 - - [30/Jul/2017:12:54:37 +0800] &quot;GET /MyDemoWeb/oracle.jsp HTTP/1.1&quot; 200 242    //192.168.88.1 - - [30/Jul/2017:12:54:38 +0800] &quot;GET /MyDemoWeb/hadoop.jsp HTTP/1.1&quot; 200 242    //192.168.88.1 - - [30/Jul/2017:12:54:38 +0800] &quot;GET /MyDemoWeb/java.jsp HTTP/1.1&quot; 200 240    val data = file.map(x =&gt; {        //按&quot;切分        val line = x.split(&quot;\&quot;&quot;)        //切分开取第二个数据，再按/切分        val line2 = line(1).split(&quot;/&quot;)        //取切分后的第三个个数据再按空格切分后取第一个数据即head.jsp        //变为tuple形式(xx,1)返回        (line2(2).split(&quot;\\s+&quot;)(0), 1)    }).collect.filter(_._1 != &quot;&quot;)    //filter即取出数据为不为空的信息，起到过滤的作用    //做wordCount    val data2 = data.groupBy(_._1).map(x =&gt; {    //map后数据类型是    //x.1-&gt;String    //x.2是Array(String,Int)    //所以对x.2再遍历求和即得到出现的次数    (x._1, x._2.map(x =&gt; x._2).sum)    }).toArray    //返回的是数组形式    //JDBC访问mysql数据库，调用了MysqlUtils类获取连接和关闭链接    //并使用了批处理executeBatch(),addBatch()    //相比于executeUpdate()效率更高    var conn: Connection = null    var psts: PreparedStatement = null    //jdbc    try {        //调用getConnect()获取链接        conn = MySqlUtils.getConnect()        //执行sql语句        val psts = conn.prepareStatement(&quot;insert into test01 values(?,?)&quot;)        for (i &lt;- 0 to data2.length - 1) {            psts.setString(1, s&quot;${data2(i)._1}&quot;)            psts.setInt(2, data2(i)._2)            // 这样，更新10000条数据，就得访问数据库10000次,造成io的负载，数据量一大会明显察觉速度变慢            psts.executeUpdate()            //psts.setString(1, s&quot;${data2(i)._1}&quot;)            //psts.setInt(2, data2(i)._2)            //psts.addBatch()//添加到同一个批处理中        }        //批处理 executeBatch() 批量写入，降低IO，提高性能        //psts.executeBatch()//执行批处理        conn.commit(); //执行完后，手动提交事务        conn.setAutoCommit(true); //在把自动提交打开    } catch {        case e: Exception =&gt; e.printStackTrace()    } finally {        //调用closeRes()关闭链接        MySqlUtils.closeRes(conn, null, psts)    }}}</code></pre></li></ul></li></ol><ol start="3"><li><p>用spark方式链接mysql，前提是必须创建dataFrame(df)，这里以hive写入mysql为例，将hive同mysql整合起来，也是平常非常常用的一种技术</p><p> import java.util.Properties<br> import org.apache.log4j.{Level, Logger}<br> import org.apache.spark.sql.{SaveMode, SparkSession}</p><p> /**</p><ul><li><p>spark将最后一条sql语句的查询结果保存到mysql数据库中<br>*/<br>object HiveToMySql {<br>  Logger.getLogger(“org”).setLevel(Level.ERROR)</p><p>  def main(args: Array[String]): Unit = {</p><pre><code>val spark = SparkSession.builder().appName(&quot;Spark Hive Demo&quot;).master(&quot;spark://master:7077&quot;).enableHiveSupport() //支持hive，这个是关键，没有不行！.getOrCreate()//读取hive数据库内容spark.sql(&quot;use sogou&quot;)//获取dataFrameval df = spark.sql(&quot;select count(*) as mycount from sogou.sogou500w_ext&quot;)//创建properties对象，注入mysql配置val prop = new Properties()prop.put(&quot;user&quot;, &quot;spark&quot;)prop.put(&quot;password&quot;, &quot;spark&quot;)prop.put(&quot;driver&quot;, &quot;com.mysql.jdbc.Driver&quot;)//写入数据时字段名要对应上，顺序可以不与实际的表对应也就是mysql与hive的表列字段要一致df.write.mode(SaveMode.Overwrite).jdbc(&quot;jdbc:mysql://master:3306/spark&quot;, &quot;spark.bb&quot;, prop)//写入mysql时可以配置mode(插入)，overwrite(覆盖)，append(追加)，ignore(忽略)，error(默认表存在报错)常用是mode和overwrite//resultDF.write.mode(SaveMode.Overwrite).jdbc(&quot;jdbc:mysql://192.168.200.150:3306/spark&quot;,&quot;student&quot;,prop)</code></pre><p>  }<br>}</p></li></ul></li></ol><blockquote><p>以上涵盖了spark与常用关系型数据库交互的所有内容(oracle,sqlserver与mysql类似这里就不详细说明了)，希望对大家有所帮助，这也是我项目中用到最常用的几种，应该可以帮助大家快速开发项目</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这篇文章涵盖了spark与常用关系型数据库交互的所有内容(oracle,sqlserver与mysql类似这里就不详细说明了)，这也是我项目中用到最常用的几种，应该可以帮助大家快速开发项目&lt;br&gt;
    
    </summary>
    
      <category term="数据库" scheme="http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="sparkSql" scheme="http://yoursite.com/tags/sparkSql/"/>
    
  </entry>
  
  <entry>
    <title>Hbase之HMaster启动后经常掉的解决方案</title>
    <link href="http://yoursite.com/2019/02/08/Hbase%E4%B9%8BHMaster%E5%90%AF%E5%8A%A8%E5%90%8E%E7%BB%8F%E5%B8%B8%E6%8E%89%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"/>
    <id>http://yoursite.com/2019/02/08/Hbase之HMaster启动后经常掉的解决方案/</id>
    <published>2019-02-08T11:08:03.000Z</published>
    <updated>2019-02-08T11:19:11.728Z</updated>
    
    <content type="html"><![CDATA[<h2 id="在Hbase-shell中执行命令list之后报了一串错误…如何解决？"><a href="#在Hbase-shell中执行命令list之后报了一串错误…如何解决？" class="headerlink" title="在Hbase-shell中执行命令list之后报了一串错误…如何解决？"></a>在Hbase-shell中执行命令list之后报了一串错误…如何解决？</h2><ul><li><pre><code>SLF4J: Class path contains multiple SLF4J bindings.SLF4J: Found binding in [jar:file:/home/xdl/hbase-0.98.9-hadoop2/lib/slf4j-log4j12-1.6.4.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: Found binding in [jar:file:/home/xdl/hadoop-2.5.2/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.2018-10-19 05:31:49,934 WARN  [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable--以上是因为Hadoop的依赖包与hbase的依赖包中的jar包相同，不影响启动关键在于下面的异常：</code></pre></li><li><p>服务起不来，看一下具体报错</p><pre><code>ERROR: org.apache.hadoop.hbase.ipc.ServerNotRunningYetException: Server is not running yetServer is not running yet 服务起不来--第一个想到的方法是关闭hbase重新启动stop-hbase.shstart-hbase.sh</code></pre><p>  果然是没卵用的</p></li></ul><hr><ul><li><p>网上还有说是让关闭hadoop的安全模式<br>  查看hadoop的安全模式状态：</p><pre><code>hadoop dfsadmin -safemode getSafe mode is OFF</code></pre><p>  OFF：表示安全模式关闭状态，如果是ON则可以用<br>  <code>hadoop dfsadmin -safemode leave</code> 命令来关闭安全模式</p></li></ul><hr><ul><li><p>果然第二个方法也没用，那换第三个方法，网上还有说是hbase的依赖包与hadoop的依赖包重复让删除hbase中的重复的依赖包：</p><pre><code>slf4j-log4j12-1.6.4.jarslf4j-api-1.6.4.jar</code></pre><p>  果然删了以后还是没卵用<br>  那么list后出现的ERROR最有用的是 ZOOKEEPER的问题：<br>  <code>ERROR:can&#39;t get master address from ZooKeeper; znode data == null</code><br>  那我们就从这里入手，从zookeeper的data路径： (三个节点都删)(这里以三个节点(1主2从)为例)<br>  <code>/home/zkpk/zookeeper-3.4.5/data</code> 下的 <code>myid zookeeper_server.pid</code> 除了myid以外的其他文件都删掉<br>  然后重启zookeeper ： <code>zkServer.sh restart</code> (三个节点都重启zookeeper)<br>  这时候应该不会报:<code>ERROR:can&#39;t get master address from ZooKeeper; znode data == null</code>这个错误了<br>  而且HMaster也应该不会掉了(其实我的HMaster在我每次进入hbase shell 后 list 后就掉了…)<br>  但当你再进入 hbase shell 再 list时还可能报：<code>ERROR: org.apache.hadoop.hbase.ipc.ServerNotRunningYetException: Server is not running yet</code> 这个错误<br>  解决方法就是：格式化namenode (我就是这样好的)，如何格式化？<br> <code>hadoop namenode -format</code><br>  然后启动Hadoop集群(<code>start-all.sh</code>)，zookeeper(前面重启过zookeeper，这里就不用重启了)，hbase(<code>start-hbase.sh</code>{这里说一嘴，关闭hbase时从节点上的HRegionServer关不掉可以直接KILL -9 掉它})<br>  再进入<code>hbase shell</code>中去测试吧，应该没问题了！！</p></li></ul><blockquote><p>总结一下，出了错不要总是在Hbase上找问题，关键要去集群环境，zookeeper环境上寻找，最坏的做法就是格式化集群，这样会导致hdfs上的文件清空，还有就是zookeeper文件夹下的data文件夹里面的内容除了配置的myid不需要删以外，其他的都删掉，你下次再启动zookeeper后会自动生成所以不太影响，但问题往往会出在这里，多试一些方法，解决问题最重要</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;在Hbase-shell中执行命令list之后报了一串错误…如何解决？&quot;&gt;&lt;a href=&quot;#在Hbase-shell中执行命令list之后报了一串错误…如何解决？&quot; class=&quot;headerlink&quot; title=&quot;在Hbase-shell中执行命令list之
      
    
    </summary>
    
    
      <category term="Hbase" scheme="http://yoursite.com/tags/Hbase/"/>
    
  </entry>
  
  <entry>
    <title>结构化数据、半结构化数据和非结构化数据</title>
    <link href="http://yoursite.com/2019/02/07/%E7%BB%93%E6%9E%84%E5%8C%96%E6%95%B0%E6%8D%AE%E3%80%81%E5%8D%8A%E7%BB%93%E6%9E%84%E5%8C%96%E6%95%B0%E6%8D%AE%E5%92%8C%E9%9D%9E%E7%BB%93%E6%9E%84%E5%8C%96%E6%95%B0%E6%8D%AE/"/>
    <id>http://yoursite.com/2019/02/07/结构化数据、半结构化数据和非结构化数据/</id>
    <published>2019-02-06T16:03:51.000Z</published>
    <updated>2019-02-18T09:46:17.493Z</updated>
    
    <content type="html"><![CDATA[<h2 id="结构化数据、半结构化数据和非结构化数据"><a href="#结构化数据、半结构化数据和非结构化数据" class="headerlink" title="结构化数据、半结构化数据和非结构化数据"></a>结构化数据、半结构化数据和非结构化数据</h2><p>什么是结构化数据、半结构化数据和非结构化数据？</p><p>(1)结构化数据<br>结构化的数据是指可以使用关系型数据库表示和存储，表现为二维形式的数据。一般特点是：数据以行为单位，一行数据表示一个实体的信息，每一行数据的属性是相同的。举一个例子：</p><pre><code>id      name    age     gender1       lyg     12      male2       liangym 13      female3       liang   18      male所以，结构化的数据的存储和排列是很有规律的，这对查询和修改等操作很有帮助。但是，显然，它的扩展性不好（比如，我希望增加一个字段，怎么办？）。</code></pre><p>(2)半结构化数据</p><pre><code>半结构化数据是结构化数据的一种形式，它并不符合关系型数据库或其他数据表的形式关联起来的数据模型结构，但包含相关标记，用来分隔语义元素以及对记录和字段进行分层。因此，它也被称为自描述的结构。半结构化数据，属于同一类实体可以有不同的属性，即使他们被组合在一起，这些属性的顺序并不重要。常见的半结构数据有XML和JSON，对于对于两个XML文件，第一个可能有&lt;person&gt;    &lt;name&gt;A&lt;/name&gt;    &lt;age&gt;13&lt;/age&gt;    &lt;gender&gt;female&lt;/gender&gt;&lt;/person&gt;第二个可能为：&lt;person&gt;    &lt;name&gt;B&lt;/name&gt;    &lt;gender&gt;male&lt;/gender&gt;&lt;/person&gt;从上面的例子中，属性的顺序是不重要的，不同的半结构化数据的属性的个数是不一定一样的。有些人说半结构化数据是以树或者图的数据结构存储的数据，怎么理解呢？上面的例子中，&lt;person&gt;标签是树的根节点，&lt;name&gt;和&lt;gender&gt;标签是子节点。通过这样的数据格式，可以自由地表达很多有用的信息，包括自我描述信息（元数据）。所以，半结构化数据的扩展性是很好的。</code></pre><p>(3)非结构化数据</p><pre><code>顾名思义，就是没有固定结构的数据。各种文档、图片、视频/音频等都属于非结构化数据。对于这类数据，我们一般直接整体进行存储，而且一般存储为二进制的数据格式。</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;结构化数据、半结构化数据和非结构化数据&quot;&gt;&lt;a href=&quot;#结构化数据、半结构化数据和非结构化数据&quot; class=&quot;headerlink&quot; title=&quot;结构化数据、半结构化数据和非结构化数据&quot;&gt;&lt;/a&gt;结构化数据、半结构化数据和非结构化数据&lt;/h2&gt;&lt;p&gt;什么
      
    
    </summary>
    
      <category term="面经" scheme="http://yoursite.com/categories/%E9%9D%A2%E7%BB%8F/"/>
    
    
      <category term="面试题" scheme="http://yoursite.com/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"/>
    
  </entry>
  
  <entry>
    <title>如何实现单点登录验证功能</title>
    <link href="http://yoursite.com/2019/02/03/%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%8D%95%E7%82%B9%E7%99%BB%E5%BD%95%E9%AA%8C%E8%AF%81%E5%8A%9F%E8%83%BD/"/>
    <id>http://yoursite.com/2019/02/03/如何实现单点登录验证功能/</id>
    <published>2019-02-02T18:36:42.000Z</published>
    <updated>2019-02-05T17:45:11.867Z</updated>
    
    <content type="html"><![CDATA[<h2 id="单点登录-SSO-gt-Single-Sign-On"><a href="#单点登录-SSO-gt-Single-Sign-On" class="headerlink" title="单点登录(SSO =&gt; Single Sign On)"></a>单点登录(SSO =&gt; Single Sign On)</h2><blockquote><p>单点登录SSO是指Single Sign On 从一个系统登录，其他系统免登录，在一个系统用户增多，架构完善之后为了方便运营人员登录多个系统而不需要每次都输入用户名密码，所以实现单点登录显得尤为重要，这里分享一下我在项目中如何用单点登录实现用户登录一次即可访问其他相互信任的系统</p></blockquote><ol><li>首先我们的认证系统是独立的一个模块，即我们在用户登录后，会调用认证系统的方法来生成用户唯一的session并进行保存，认证系统返回给客户端一个唯一的登录凭证，用这个登录凭证即可直接访问其他的子系统不用再进行登录了</li></ol><img src="/2019/02/03/如何实现单点登录验证功能/SSO.jpg" title="SSO单点登录"><ol start="2"><li><p>在进行登录认证返回登录凭证后，我们还需要配置一个拦截器，用于拦截服务的请求，即我们需要哪些请求要验证这个登录凭证才能访问我们的其他服务，这样写可能不是很清楚，举个栗子</p><ul><li>用户A登录网站，以post请求访问/xxx/login，再登录的同时去注册验证系统，返回一个登录状态(成功登录or失败)并附带一个登录验证后的凭证，这个凭证代表A可以访问其他的子服务</li><li><p>当用户A访问B服务时拦截器起作用，拦截器控制如果想访问B服务，需要验证这个凭证是否生效，如果生效则放行，这就是单点登录如何通过配置拦截器控制访问的实现流程</p><pre><code>public class CheckInterceptor implements HandlerInterceptor {    //发请求 restTemplate    //专门调rest服务的对象    @Autowired    private RestTemplate restTemplate;    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler)            throws Exception {        //截取请求中的userId,ticket        //ticket为凭证,这里凭证已经通过登录系统保存至浏览器,我们直接取即可        String userId = request.getParameter(&quot;userId&quot;);        String ticket = request.getParameter(&quot;ticket&quot;);        // 将userId,ticket发给/user/ticket检测        //返回结果是ReturnResult对象        if(userId!=null&amp;&amp;ticket!=null){            //这里是拦截器需要访问这个请求,并设置参数进行验证            String url = &quot;http://localhost:7001/user/ticket&quot;;            MultiValueMap&lt;String, Object&gt; params = new LinkedMultiValueMap&lt;&gt;();            params.set(&quot;userId&quot;, userId);            params.set(&quot;ticket&quot;, ticket);            ReturnResult result = restTemplate.postForObject(url, params, ReturnResult.class);            //返回结果的判断            if(result.getStatus()==yixueConstant.SUCCESS){                //校验正确,放行                return true;            }        }        //校验失败,拦截请求,给用户返回一个json结果        response.setContentType(&quot;text/html;Charset=UTF-8&quot;);        PrintWriter out = response.getWriter();        out.print(&quot;{\&quot;status\&quot;:-2,\&quot;msg\&quot;:\&quot;令牌凭证无效\&quot;}&quot;);        out.flush();        return false;    }}</code></pre></li><li><p>有了拦截器，我们还要把拦截器加入配置，使其生效</p><pre><code>@Componentpublic class CheckInterceptorConfiguration implements WebMvcConfigurer {    @Autowired    private CheckInterceptor checkInterceptor;    public void addInterceptors(InterceptorRegistry registry) {        //添加要拦截的请求地址url，在我们访问视频模块时，需要先拦截请求，在拦截器中验证，如果返回结果为true则放行        String[] urls = {&quot;/course/chapter&quot;};        registry.addInterceptor(checkInterceptor).addPathPatterns(urls);    }}</code></pre></li></ul></li></ol><p>具体的完整流程（凭证的生成及存储）请参考我的<a href="https://ymliang.netlify.com/2019/02/03/%E6%B5%85%E8%B0%88%E9%A1%B9%E7%9B%AE%E4%B8%AD%E7%94%A8%E5%88%B0redis%E7%9A%84%E5%9C%B0%E6%96%B9/" target="_blank" rel="noopener">另外一篇文章</a></p><p>这里我分享另外一篇技术博客给大家方便大家理解<a href="https://blog.csdn.net/qq_39089301/article/details/80615348" target="_blank" rel="noopener">单点登录</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;单点登录-SSO-gt-Single-Sign-On&quot;&gt;&lt;a href=&quot;#单点登录-SSO-gt-Single-Sign-On&quot; class=&quot;headerlink&quot; title=&quot;单点登录(SSO =&amp;gt; Single Sign On)&quot;&gt;&lt;/a&gt;单点登录
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>浅谈项目中用到redis的地方</title>
    <link href="http://yoursite.com/2019/02/03/%E6%B5%85%E8%B0%88%E9%A1%B9%E7%9B%AE%E4%B8%AD%E7%94%A8%E5%88%B0redis%E7%9A%84%E5%9C%B0%E6%96%B9/"/>
    <id>http://yoursite.com/2019/02/03/浅谈项目中用到redis的地方/</id>
    <published>2019-02-02T18:32:38.000Z</published>
    <updated>2019-02-04T17:14:42.175Z</updated>
    
    <content type="html"><![CDATA[<h2 id="之前和几个朋友在开发网站时用到了redis数据库，这里分享干货给大家，废话不多说直接上代码"><a href="#之前和几个朋友在开发网站时用到了redis数据库，这里分享干货给大家，废话不多说直接上代码" class="headerlink" title="之前和几个朋友在开发网站时用到了redis数据库，这里分享干货给大家，废话不多说直接上代码"></a>之前和几个朋友在开发网站时用到了redis数据库，这里分享干货给大家，废话不多说直接上代码</h2><blockquote><p>我们用到redis的地方是在验证登录时的一个小demo，思路是每个用户登录到网站时给这个用互提供一个唯一的校验码ticket，之后存到redis中在后续访问网站相关内容时要取出ticket进行验证方可继续访问</p></blockquote><p>生成ticket</p><ul><li><p>entity层</p><ul><li><p>Ticket.java</p><pre><code>private Integer userId;//用户idprivate String userName;//用户名private String token;//ticket编号private long createTime;//创建时间private long expire;//有效期public String toString() {// token+createTime+expire+userId+userNameString str = token + &quot;-&quot; + createTime + &quot;-&quot; + expire + &quot;-&quot; + userId;//利用Base64算法处理String base64Str = Base64Utils.encodeToString(str.getBytes()); return base64Str;}...get,set方法自己生成吧</code></pre></li></ul></li></ul><p>这里用到了<a href="https://blog.csdn.net/ventry/article/details/3066859?utm_source=blogxgwz3" target="_blank" rel="noopener">Base64算法</a>封装ticket，便于验证时的比较</p><ul><li><p>service层</p><ul><li><p>TicketManager.java//管理ticket的TickManager类，有创建ticket的方法和检验ticket的方法</p><pre><code>@Componentpublic class TicketManager {@Autowiredprivate RedisTemplate&lt;Object, Object&gt; redis;public Ticket create(User user, int hour) {    Ticket ticket = new Ticket();    ticket.setUserId(user.getId());    ticket.setUserName(user.getName());    ticket.setCreateTime(System.currentTimeMillis());    ticket.setExpire(hour * 3600 * 1000);// 有效时长    ticket.setToken(UUID.randomUUID().toString());    // 将ticket存入redis,方便将来验证    // redis.opsForValue().set(&quot;ticket_&quot;+user.getId(), t);    redis.opsForHash().put(&quot;tickers&quot;, user.getId(), ticket);    // 测试取userId    Ticket t = (Ticket) redis.opsForHash().get(&quot;tickers&quot;, user.getId());    System.out.println(&quot;从redis中读取=&gt;:&quot;+t);    return ticket;}public int checkTicket(int userId, String ticket) {    Ticket t = (Ticket) redis.opsForHash().get(&quot;tickers&quot;, userId);    System.out.println(&quot;|--------------------------------------------------------------------------------------------------|&quot;);    System.out.println(&quot;|从redis中读取=&gt;:&quot;+t.toString()+&quot;|&quot;);    System.out.println(&quot;|--------------------------------------------------------------------------------------------------|&quot;);    System.out.println(&quot;|从request带来=&gt;:&quot;+ticket.toString()+&quot;|&quot;);    System.out.println(&quot;|--------------------------------------------------------------------------------------------------|&quot;);    System.out.println(&quot;|&quot;+t.toString().equals(ticket)+&quot;|&quot;);    System.out.println(&quot;|--------------------------------------------------------------------------------------------------|&quot;);    // 检测ticket是否匹配    if (t != null &amp;&amp; t.toString().equals(ticket)) {        // 匹配成功        long currentTime = System.currentTimeMillis();        long totalTime = t.getCreateTime() + t.getExpire();        // 检测是否失效        if (currentTime &lt; totalTime) {            // 在有效期内   0            return yixueConstant.SUCCESS;        } else {            // 过期  1            return yixueConstant.ERROR1;        }    }    // 不匹配    -1     return yixueConstant.ERROR;}}   </code></pre><p>这里用到了Java访问Redis的方法因为网站是用SpringBoot开发的，boot也提供了访问redis的包 <code>spring-boot-starter-data-redis</code></p><p>这里我提供boot访问redis的方法：</p></li><li><p>需要添加SpringData-redis包，它提供一个RedisTemplate对象使用。</p></li><li><p>引入spring-boot-starter-data-redis工具包(Maven项目中的pom.xml中添加)</p><pre><code>&lt;parent&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;    &lt;version&gt;2.0.1.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;properties&gt;    &lt;java.version&gt;1.8&lt;/java.version&gt;&lt;/properties&gt;&lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;redis.clients&lt;/groupId&gt;        &lt;artifactId&gt;jedis&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;junit&lt;/groupId&gt;        &lt;artifactId&gt;junit&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;</code></pre></li><li><p>在application.properties配置redis连接参数(resources文件夹下的application.properties配置文件)</p><pre><code>spring.redis.host=localhostspring.redis.port=6379</code></pre></li><li><p>注入使用RedisTemplate对象(这是测试类，测试能否存储到redis中和能否取出)</p><pre><code>@RunWith(SpringRunner.class)@SpringBootTest(classes={MyBootApplication.class})public class TestRedisTemplate {    @Autowired    private RedisTemplate&lt;Object, Object&gt; redis;    @Test    public void test1(){        redis.opsForValue().set(&quot;msg1&quot;, &quot;redis&quot;);        String value = (String)redis.opsForValue().get(&quot;msg1&quot;);        System.out.println(value);    }}</code></pre></li><li><p>接着我们在service接口添加方法，这个方法是检验ticket是否合法和是否超时</p><pre><code>/*** 检查凭证是否合法或超时功能的实现* @param userId 用户唯一ID* @param ticket 用户登录后唯一凭证* @return*/public ReturnResult checkTicket(int userId,String ticket);</code></pre></li><li><p>在实现类serviceImp中注入ticketManager对象</p><pre><code>@Autowiredprivate TicketManager ticketManager;</code></pre></li><li><p>在实现类serviceImp中有用户登录的方法和检验ticket的方法，我们需要在用户登录方法中调用create方法来实现用户每次登录时都创建一个唯一的ticket作为凭证，用户如果要想访问网站其他内容必须要经过ticket的校验，这一点我们后面用拦截器来实现</p><pre><code>/*** 登录功能实现*/@Overridepublic ReturnResult checkUser(String name, String password) {    ReturnResult result = new ReturnResult();    // 检验参数是否合法    if (StringUtils.isEmpty(name) || StringUtils.isEmpty(password)) {        // 用yixueConstant常量类替换        // (yixueConstant.ERROR -&gt; 参数错误        // yixueConstant.PARAM_ERROR-&gt;&quot;参数不合法&quot;）        result.setStatus(yixueConstant.ERROR);        result.setMsg(yixueConstant.PARAM_ERROR);        return result;    }    // 检查账户是否存在    User user = userDao.selectByName(name);    if (user == null) {        // 不存在        result.setStatus(yixueConstant.ERROR1);        result.setMsg(yixueConstant.LOGIN_NAME_ERROR);        return result;    }    // 检验密码是否正确    String salt = user.getSalt();    String md5Password = PasswordUtil.md5(password + salt);    if (!user.getPassword().equals(md5Password)) {        result.setStatus(yixueConstant.ERROR2);        result.setMsg(yixueConstant.LOGIN_PASSWORD_ERROR);        return result;    }    // 账户和密码都正确    result.setStatus(yixueConstant.SUCCESS);    result.setMsg(yixueConstant.LOGIN_SUCCESS);    //---关键代码----    // 若登录成功即(账户和密码都正确),则创建一个ticket返回,有效期2小时    Ticket ticket = ticketManager.create(user,2);    Map&lt;String, Object&gt; map = new HashMap&lt;&gt;();    map.put(&quot;userId&quot;, ticket.getUserId());    //这里我们把ticket的toString方法的返回值放进map中了，也就是base64算法封装后的ticket    map.put(&quot;ticket&quot;, ticket.toString());    //---关键代码----    result.setData(map);    //返回的result是返回给浏览器，浏览器把ticket保存下来，继续后续的业务校验工作    return result;}/*** 检查凭证是否合法或超时功能* */@Overridepublic ReturnResult checkTicket(int userId, String ticket) {    ReturnResult result = new ReturnResult();    int num = ticketManager.checkTicket(userId, ticket);    if (num == yixueConstant.SUCCESS){        // 凭证在有效期内        result.setStatus(num);        result.setMsg(yixueConstant.TICKETS_SUCCESS);        return result;    }else if(num == yixueConstant.ERROR1){        //凭证过时        result.setStatus(num);        result.setMsg(yixueConstant.TICKETS_ERROR_OVERTIME);        return result;    }    //凭证不匹配    result.setStatus(num);    result.setMsg(yixueConstant.TICKETS_ERROR);    return result;}</code></pre></li><li><p>returnResult 对象是 ReturnResult类的对象，是为了给浏览器返回一个状态码，状态信息，和数据内容，我们用ajax来取出传来的data信息进行前端的展示</p><pre><code>private int status;private String msg;private Object data;</code></pre></li></ul></li></ul><pre><code>- Controller层中注入service并添加方法，这个方法也就是我们后面如果有请求被拦截，都会调用这个方法来进行校验的        @Autowired        private UserService userService;        @PostMapping(&quot;/user/ticket&quot;)        public ReturnResult ticket(                @RequestParam(name = &quot;userId&quot;, required = false) int userId,                @RequestParam(name = &quot;ticket&quot;, required = false) String ticket) {            ReturnResult result = userService.checkTicket(userId,ticket);            return result;        }- 之后我们如果想拦截用户访问其他模块的请求，就在相应的模块中添加拦截器，这里以访问视频模块为例，在视频模块中添加intercepter拦截器        public class CheckInterceptor implements HandlerInterceptor {            //发请求 restTemplate            //专门调rest服务的对象            @Autowired            private RestTemplate restTemplate;            public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler)                    throws Exception {                //截取请求中的userId,ticket                String userId = request.getParameter(&quot;userId&quot;);                String ticket = request.getParameter(&quot;ticket&quot;);                // 将userId,ticket发给/user/ticket检测                //返回结果是ReturnResult对象                if(userId!=null&amp;&amp;ticket!=null){                    String url = &quot;http://localhost:7001/user/ticket&quot;;                    MultiValueMap&lt;String, Object&gt; params = new LinkedMultiValueMap&lt;&gt;();                    params.set(&quot;userId&quot;, userId);                    params.set(&quot;ticket&quot;, ticket);                    ReturnResult result = restTemplate.postForObject(url, params, ReturnResult.class);                    if(result.getStatus()==yixueConstant.SUCCESS){                        //校验正确,放行                        return true;                    }                }                //校验失败,拦截请求,给用户返回一个json结果                response.setContentType(&quot;text/html;Charset=UTF-8&quot;);                PrintWriter out = response.getWriter();                out.print(&quot;{\&quot;status\&quot;:-2,\&quot;msg\&quot;:\&quot;令牌凭证无效\&quot;}&quot;);                out.flush();                return false;            }        }- 有了拦截器，我们还要把拦截器加入配置，使其生效        @Component        public class CheckInterceptorConfiguration implements WebMvcConfigurer {            @Autowired            private CheckInterceptor checkInterceptor;            public void addInterceptors(InterceptorRegistry registry) {                //添加要拦截的请求地址url，在我们访问视频模块时，需要先拦截请求，在拦截器中验证，如果返回结果为true则放行                String[] urls = {&quot;/course/chapter&quot;};                registry.addInterceptor(checkInterceptor).addPathPatterns(urls);            }        }到这里大致就结束了，其实用到redis的地方就是springBoot访问redis的包，和访问redis的几行代码，这里稍微总结一下：    @Autowired    private RedisTemplate&lt;Object, Object&gt; redis;注入并使用RedisTemplate对象- 存到redis中`redis.opsForHash().put(&quot;tickers&quot;, user.getId(), ticket);`- 取出`redis.opsForHash().get(&quot;tickers&quot;, user.getId());`也就是我们在用户登录是要create一个ticket存入redis中，然后在checkTicket时我们从redis取出ticket做校验，如果相同再去校验是否超时达到单点登录的功能</code></pre><hr><p>这里附一个<a href="http://www.runoob.com/redis/redis-conf.html" target="_blank" rel="noopener">redis的教程</a>供大家参考</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;之前和几个朋友在开发网站时用到了redis数据库，这里分享干货给大家，废话不多说直接上代码&quot;&gt;&lt;a href=&quot;#之前和几个朋友在开发网站时用到了redis数据库，这里分享干货给大家，废话不多说直接上代码&quot; class=&quot;headerlink&quot; title=&quot;之前
      
    
    </summary>
    
    
      <category term="redis" scheme="http://yoursite.com/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>SparkSQL分析</title>
    <link href="http://yoursite.com/2019/02/03/SparkSQL%E9%9D%A2%E8%AF%95%E9%A2%98/"/>
    <id>http://yoursite.com/2019/02/03/SparkSQL面试题/</id>
    <published>2019-02-02T16:05:30.000Z</published>
    <updated>2019-05-15T02:37:47.714Z</updated>
    
    <content type="html"><![CDATA[<blockquote></blockquote><p>SparkSql作为Spark的结构化数据处理模块，提供了非常强大的API，让分析人员用一次，就会为之倾倒，为之着迷，为之至死不渝。在内部，SparkSQL使用额外结构信息来执行额外的优化。在外部，可以使用SQL和DataSet 的API与之交互。<br><a id="more"></a></p><h2 id="简单排名函数的使用"><a href="#简单排名函数的使用" class="headerlink" title="简单排名函数的使用"></a>简单排名函数的使用</h2><p>昨天和今天都登录了的用户id<br>昨天登录了但是今天没有登录的用户id</p><pre><code>--ds1 中的数据代表昨天登录的用户id--ds2 中的数据代表今天登录的用户id--准备数据val ds1 = spark.range(0,20)val ds2 = spark.range(10,30)ds1.createOrReplaceTempView(&quot;t1&quot;)ds2.createOrReplaceTempView(&quot;t2&quot;)--求：--1. 昨天和今天都登录了的用户id--2. 昨天登录了但是今天没有登录的用户id--1. 这里用的是简单的表连接求交集,比较简单,如果看不懂可以把sql语句拆开看效果sql(&quot;&quot;&quot;select id1 from(select t1.id as id1,if(isnull(t2.id),&apos;未出现&apos;,t2.id) as id2 from t1 left join t2 on t1.id = t2.id)where id1 = id2&quot;&quot;&quot;).show+---+|id1|+---+| 10|| 11|| 12|| 13|| 14|| 15|| 16|| 17|| 18|| 19|+---+--2. 在1的基础上稍微变一下,因为求第一天出现第二天没出线时只需要满足第二天的=未出现即可,sql(&quot;&quot;&quot;select id1 from(select t1.id as id1,if(isnull(t2.id),&apos;未出现&apos;,t2.id) as id2 from t1 left join t2 on t1.id = t2.id)where id2 = &apos;未出现&apos;&quot;&quot;&quot;).show+---+     |id1|+---+|  0||  1||  2||  3||  4||  5||  6||  7||  8||  9|+---+--3. 如果是求第二天出现第一天未出现的话t1 t2换个位置就好了sql(&quot;&quot;&quot;select id2 from(select if(isnull(t1.id),&apos;未出现&apos;,t1.id) as id1,t2.id as id2 from t1 right join t2 on t1.id = t2.id)where id1 = &apos;未出现&apos;&quot;&quot;&quot;).show+---+|id2|+---+| 20|| 21|| 22|| 23|| 24|| 25|| 26|| 27|| 28|| 29|+---+</code></pre><blockquote><p>这里如果对isnull函数不理解的话可以参考我写的,逻辑就是如果(if)字段为空isnull(字段),就替换为’未出现’ 否则还是原有字段,好像还有其他写法,大家自行百度吧,达到需求就可以了</p></blockquote><p><code>if(isnull(t1.id),&#39;未出现&#39;,t1.id)</code></p><h2 id="每个部门工资最高的前3名"><a href="#每个部门工资最高的前3名" class="headerlink" title="每个部门工资最高的前3名"></a>每个部门工资最高的前3名</h2><pre><code>--这个数据表头是csv文件格式便于sparksql进行自动类型匹配EMPNO,ENAME,JOB,MGR,HIREDATE,SAL,COMM,DEPTNO7369,SMITH,CLERK,7902,2001-01-02 22:12:13,800,,207499,ALLEN,SALESMAN,7698,2002-01-02 22:12:13,1600,300,307521,WARD,SALESMAN,7698,2003-01-02 22:12:13,1250,500,307566,JONES,MANAGER,7839,2004-01-02 22:12:13,2975,,207654,MARTIN,SALESMAN,7698,2005-01-02 22:12:13,1250,1400,307698,BLAKE,MANAGER,7839,2005-04-02 22:12:13,2850,,307782,CLARK,MANAGER,7839,2006-03-02 22:12:13,2450,,107788,SCOTT,ANALYST,7566,2007-03-02 22:12:13,3000,,207839,KING,PRESIDENT,,2006-03-02 22:12:13,5000,,107844,TURNER,SALESMAN,7698,2009-07-02 22:12:13,1500,0,307876,ADAMS,CLERK,7788,2010-05-02 22:12:13,1100,,207900,JAMES,CLERK,7698,2011-06-02 22:12:13,950,,307902,FORD,ANALYST,7566,2011-07-02 22:12:13,3000,,207934,MILLER,CLERK,7782,2012-11-02 22:12:13,1300,,10--最后达到的要求+------+----+----+----+|deptno|sal1|sal2|sal3|+------+----+----+----+|    10|5000|2450|1300||    20|3000|3000|2975||    30|2850|1600|1500|+------+----+----+----+--(&quot;header&quot;, true)表示如果这个是数据本身是有列名的就按第一行的列名去建表,列名就是这个文件的第一行的每个单词--(&quot;inferschema&quot;, true)表示自动类型推断,我们可以用df.printSchema来看spark给我们匹配的类型是什么--.csv(&quot;hdfs://master:9000/data/a.log&quot;)val df = spark.read.option(&quot;header&quot;,true).option(&quot;inferschema&quot;,true).csv(&quot;hdfs://master:9000/data/a.log&quot;)--建临时表df.createOrReplaceTempView(&quot;temp&quot;)</code></pre><p><code>row_number() over()</code> –&gt; <a href="https://www.cnblogs.com/liuzhenlei/p/8026278.html" target="_blank" rel="noopener">排名函数的用法</a></p><pre><code>--这里我都是分布来算的,便于自己理清思路,同时用多层子查询时这样写思路会很清晰sql(&quot;&quot;&quot;select deptno,sal,row_number() over(partition by deptno order by sal desc) as salnum from temp having salnum &lt; 4&quot;&quot;&quot;).show+------+----+------+                                                            |deptno| sal|salnum|+------+----+------+|    20| 800|     1||    20|1100|     2||    20|2975|     3||    10|1300|     1||    10|2450|     2||    10|5000|     3||    30| 950|     1||    30|1250|     2||    30|1250|     3|+------+----+------+</code></pre><p><code>collect_list(sal)</code> <a href="http://www.cnblogs.com/cc11001100/p/9043946.html" target="_blank" rel="noopener">列转行</a> 配合group by来使用</p><pre><code>sql(&quot;&quot;&quot;select deptno,collect_list(sal) as sal from(select deptno,sal,row_number() over(partition by deptno order by sal desc) as salnum from temp having salnum &lt; 4)group by deptnoorder by deptno&quot;&quot;&quot;).show+------+------------------+                                                     |deptno|               sal|+------+------------------+|    10|[5000, 2450, 1300]||    20|[3000, 3000, 2975]||    30|[2850, 1600, 1500]|+------+------------------+--sal[0],sal[1],sal[2]实质上类似于数组的取值,可以把sal看作是数组,这一步与求结果无关只是展示一下怎么取值sql(&quot;&quot;&quot;select deptno,sal[0],sal[1],sal[2] from(select deptno,collect_list(sal) as sal from(select deptno,sal,row_number() over(partition by deptno order by sal desc) as salnum from temp having salnum &lt; 4)group by deptno)order by deptno&quot;&quot;&quot;).show+------+------+------+------+                                                   |deptno|sal[0]|sal[1]|sal[2]|+------+------+------+------+|    10|  5000|  2450|  1300||    20|  3000|  3000|  2975||    30|  2850|  1600|  1500|+------+------+------+------+--求每个部门的最高工资--first_value(sal)  sal中的第一个值sql(&quot;&quot;&quot;select distinct deptno,first from (select deptno,sal,first_value(sal) over(partition by deptno order by sal desc) as first from temp)order by deptno&quot;&quot;&quot;).show+------+-----+                                                                  |deptno|first|+------+-----+|    10| 5000||    20| 3000||    30| 2850|+------+-----+--求每个部门的最低工资--求的时候order by 别加desc就好了sql(&quot;&quot;&quot;select distinct deptno,first from (select deptno,sal,first_value(sal) over(partition by deptno order by sal) as first from temp)order by deptno&quot;&quot;&quot;).show+------+-----+                                                                  |deptno|first|+------+-----+|    10| 1300||    20|  800||    30|  950|+------+-----+</code></pre><h2 id="求NBA球队连冠记录是在哪年到哪年"><a href="#求NBA球队连冠记录是在哪年到哪年" class="headerlink" title="求NBA球队连冠记录是在哪年到哪年"></a>求NBA球队连冠记录是在哪年到哪年</h2><pre><code>--这个数据与上一题的数据格式一样的team,y活塞,1990公牛,1991公牛,1992公牛,1993火箭,1994火箭,1995公牛,1996公牛,1997公牛,1998马刺,1999湖人,2000湖人,2001湖人,2002马刺,2003活塞,2004马刺,2005热火,2006马刺,2007凯尔特人,2008湖人,2009湖人,2010--最终数据+----+------+------+|team|min(y)|max(y)|+----+------+------+|公牛|  1991|  1993||火箭|  1994|  1995||公牛|  1996|  1998||湖人|  2000|  2002||湖人|  2009|  2010|+----+------+------+--做这个题的时候我们要清除题的要求,是求连冠的球队,连冠指的是中间不能有其他球队夺冠,必须&gt;=2才可以,而且年份要挨着val df2 = spark.read.option(&quot;header&quot;, true).option(&quot;inferschema&quot;, true).csv(&quot;hdfs://master:9000/data/team.log&quot;)df2.createOrReplaceTempView(&quot;t2&quot;)--这里我也是分步骤来求,便于理清思路--这里用了y-row_number(),为什么这么用,在于如果是连冠,row_number()加排名函数,按球队名称做partition by,用夺冠年份减去row_number得到的数就是相同的,这里比较难理解,如果搞懂这里题也就做完了-这里的a是分组排名的序号 aa也就是 y-a的值sql(&quot;&quot;&quot;select team,y,a,aa from (select team,y,row_number() over(partition by team order by y)as a,y-row_number() over(partition by team order by y)as aa from t2)&quot;&quot;&quot;).show+----+----+---+----+  |team|   y|  a|  aa|+----+----+---+----+|  热火|2006|  1|2005||  活塞|1990|  1|1989||  活塞|2004|  2|2002||  火箭|1994|  1|1993||  火箭|1995|  2|1993||凯尔特人|2008|  1|2007||  湖人|2000|  1|1999||  湖人|2001|  2|1999||  湖人|2002|  3|1999||  湖人|2009|  4|2005||  湖人|2010|  5|2005||  公牛|1991|  1|1990||  公牛|1992|  2|1990||  公牛|1993|  3|1990||  公牛|1996|  4|1992||  公牛|1997|  5|1992||  公牛|1998|  6|1992||  马刺|1999|  1|1998||  马刺|2003|  2|2001||  马刺|2005|  3|2002|+----+----+---+----+--只有重复出现的连续team,之后减去row_number()后才会有相同的aa列字段 此相同的aa字段代表在相同的字段下，球队是处于连冠状态--按球队和aa分组，如果不按aa分组 那么公牛的连冠记录中间隔的几年也会被算进去,这样处理完的数据就不算是连冠的数据sql(&quot;&quot;&quot;select team,min(y) miny,max(y) maxy from(select team,y,y-row_number() over(partition by team order by y)as aa from t2)group by team,aa&quot;&quot;&quot;).show+----+----+----+|team|miny|maxy|+----+----+----+|  热火|2006|2006||  活塞|1990|1990||  活塞|2004|2004||  火箭|1994|1995||凯尔特人|2008|2008||  湖人|2000|2002||  湖人|2009|2010||  公牛|1991|1993||  公牛|1996|1998||  马刺|1999|1999||  马刺|2003|2003||  马刺|2005|2005||  马刺|2007|2007|+----+----+----+--判断最小值是否小于最大值，目的是为了排除单独一年获得冠军的球队即最小值=最大值，取出连冠过的球队--最终要尽可能的精简代码,这样会给面试官一个好印象(代码洁癖什么的???),也会显得自己sql写的很好sql(&quot;&quot;&quot;select team,min(y) miny,max(y) maxy from(select team,y,y-row_number() over(partition by team order by y)as aa from t2)group by team,aahaving min(y)&lt;max(y)order by miny&quot;&quot;&quot;).show--  大功告成+----+----+----+|team|miny|maxy|+----+----+----+|  公牛|1991|1993||  火箭|1994|1995||  公牛|1996|1998||  湖人|2000|2002||  湖人|2009|2010|+----+----+----+</code></pre><hr><blockquote><p>好啦大功告成！！！，有问题可以联系我我们一起交流<br>616581760 微信QQ同号</p></blockquote><hr>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;/blockquote&gt;
&lt;p&gt;SparkSql作为Spark的结构化数据处理模块，提供了非常强大的API，让分析人员用一次，就会为之倾倒，为之着迷，为之至死不渝。在内部，SparkSQL使用额外结构信息来执行额外的优化。在外部，可以使用SQL和DataSet 的API与之交互。&lt;br&gt;
    
    </summary>
    
      <category term="sparkSql" scheme="http://yoursite.com/categories/sparkSql/"/>
    
    
      <category term="sparkSql" scheme="http://yoursite.com/tags/sparkSql/"/>
    
  </entry>
  
  <entry>
    <title>SQL求K线波峰波谷</title>
    <link href="http://yoursite.com/2019/02/02/SQL%E6%B1%82K%E7%BA%BF%E6%B3%A2%E5%B3%B0%E6%B3%A2%E8%B0%B7/"/>
    <id>http://yoursite.com/2019/02/02/SQL求K线波峰波谷/</id>
    <published>2019-02-02T14:52:06.000Z</published>
    <updated>2019-05-06T06:56:10.242Z</updated>
    
    <content type="html"><![CDATA[<h1 id="利用SparkSQL求股市K线波峰波谷"><a href="#利用SparkSQL求股市K线波峰波谷" class="headerlink" title="利用SparkSQL求股市K线波峰波谷"></a>利用SparkSQL求股市K线波峰波谷</h1><blockquote><p>前几天朋友问了一道题我觉得还不错拿出来分享一下，如何求股市K线的波峰波谷，这里我简单分析一下我的思路，首先K线是一系列无序的数字组成的，根据每个数字与其相邻的数字之间的大小关系我们就能很轻易的求出波峰波谷，下面开始分析</p></blockquote><ol><li><p>首先数据我们用scala生成</p><ul><li><p>代码在spark-shell中写，如果在工作中大家遇到类似问题读文件取数据即可，这里简化用spark-shell代替</p><pre><code>val random = new scala.util.Random();val arr = (0 to 50).map(x=&gt;{random.nextInt(100)}).zipWithIndex</code></pre></li><li><p>zipWithIndex是在生成得随机数后在跟一个从0开始的索引组成一个个类似tuple形式的Vector容器</p><pre><code>arr//看一下打印出的类型scala&gt; res10: scala.collection.immutable.IndexedSeq[(Int, Int)] = Vector((85,0), (54,1), (69,2)......</code></pre></li><li><p>将其变为数组</p><pre><code>val arr2 = arr.toArray</code></pre></li><li><p>转化为RDD</p><pre><code>val rdd = sc.makeRDD(arr2)</code></pre></li><li><p>rdd转为DF(即DataFrame)</p><pre><code>val df = rdd.toDF(&quot;data&quot;,&quot;id&quot;)df.show+----+---+|data| id|+----+---+|  85|  0||  54|  1||  69|  2||   7|  3||  39|  4||  40|  5||  43|  6||  50|  7||  59|  8||  28|  9||  98| 10||  70| 11||  87| 12||  52| 13||   6| 14||   5| 15||  96| 16||  14| 17||  26| 18||  81| 19|+----+---+</code></pre><p>  这里show是默认显示20行数据 | show(100)可指定行数</p></li><li><p>将df建立为临时表，之后就可以用我们熟悉的sql语句操作了，提醒一下SparkSQL支持的sql是HiveSQL而它又与Oracle语法类似，但与MySQL语法有些差别</p><pre><code>df.createOrReplaceTempView(&quot;temp&quot;)</code></pre></li><li><p>为了方便观看我们将他们的列换下位置，用SQL语句的形式再建一个临时表，这种方式在操作df时很常用</p><pre><code>val df2 = sql(&quot;select id,data from temp&quot;)df2.createOrReplaceTempView(&quot;temp2&quot;)sql(&quot;select * from temp2&quot;).show+---+----+| id|data|+---+----+|  0|  85||  1|  54||  2|  69||  3|   7||  4|  39||  5|  40|</code></pre></li></ul></li><li><p>此时我们准备工作完成，开始正式写sql，大致思路为：增加两列，第一列让数列整体上移，第二列让数列整体下移这样就达到了让我们的data列的每一个数字都可以与其相邻的数字作比较的目的，之后用case when end来标识波峰波谷</p></li></ol><pre><code>- 导入隐式转换和sql函数的包        import spark.implicits._        import org.apache.spark.sql.functions        sql(&quot;&quot;&quot;        select id,data,        case when data&gt;data1 and data&gt;data2 then &apos;波峰&apos;            when data&lt;data1 and data&lt;data2 then &apos;波谷&apos;        end as data3 from(        select id,data,lead(data) over(order by id) as data1,lag(data) over(order by id) as data2 from temp2        )        &quot;&quot;&quot;).show- [case when](http://www.cnblogs.com/aipan/p/7770611.html) 用法和if else思路类似- 在这里我们用了分析函数lead()和lag()，详细用法请[点击这里](https://blog.csdn.net/pelifymeng2/article/details/70313943)，我记这些随缘，忘了就上网查一下，没必要记的太死，关键是一定要有思路        +---+----+-----+         | id|data|data3|        +---+----+-----+        |  0|  85| null|        |  1|  54|   波谷|        |  2|  69|   波峰|        |  3|   7|   波谷|        |  4|  39| null|        |  5|  40| null|        |  6|  43| null|        |  7|  50| null|        |  8|  59|   波峰|        |  9|  28|   波谷|        | 10|  98|   波峰|        | 11|  70|   波谷|        | 12|  87|   波峰|        | 13|  52| null|        | 14|   6| null|        | 15|   5|   波谷|        | 16|  96|   波峰|        | 17|  14|   波谷|        | 18|  26| null|        | 19|  81|   波峰|        +---+----+-----+</code></pre><hr><blockquote><p>好啦大功告成，有问题可以联系我我们一起交流，其实一直困扰我的问题是不知道为什么用sparkSql时子查询不给查询语句起别名也不报错，而用oracle和mysql时就会报错……<br>616581760 微信QQ同号</p></blockquote><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;利用SparkSQL求股市K线波峰波谷&quot;&gt;&lt;a href=&quot;#利用SparkSQL求股市K线波峰波谷&quot; class=&quot;headerlink&quot; title=&quot;利用SparkSQL求股市K线波峰波谷&quot;&gt;&lt;/a&gt;利用SparkSQL求股市K线波峰波谷&lt;/h1&gt;&lt;bloc
      
    
    </summary>
    
      <category term="数据库" scheme="http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="SparkSql" scheme="http://yoursite.com/tags/SparkSql/"/>
    
  </entry>
  
  <entry>
    <title>Spark最全笔记</title>
    <link href="http://yoursite.com/2019/02/02/Spark%E6%9C%80%E5%85%A8%E7%AC%94%E8%AE%B0/"/>
    <id>http://yoursite.com/2019/02/02/Spark最全笔记/</id>
    <published>2019-02-01T18:52:19.000Z</published>
    <updated>2019-02-01T19:01:58.007Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Spark简介"><a href="#Spark简介" class="headerlink" title="Spark简介"></a>Spark简介</h1><img src="/2019/02/02/Spark最全笔记/spark特点_快速.png" title="spark特点_快速"><img src="/2019/02/02/Spark最全笔记/spark特点_通用.png" title="spark特点_通用"><img src="/2019/02/02/Spark最全笔记/spark紧密集成的组建.png" title="spark紧密集成的组建"><p>三种资源管理器：Yarn、Standalone、Mesos（粗粒度、细粒度）<br>粗粒度管理模式：一次分配运行过程中的全部资源，且运行过程中要一直占用这些资源（即使不用），程序运行结束后，回收全部资源；<br>细粒度管理模式：资源按需分配。</p><h1 id="术语解释："><a href="#术语解释：" class="headerlink" title="术语解释："></a><strong>术语解释：</strong></h1><ul><li>application : spark应用程序，包含：driver(一个) + executor(多个)；</li><li>application jar</li><li>cluster manager</li><li>worker node</li><li>driver program：管理应用程序。 main() + 初始化了SparkContext；</li><li>executor ： 位于worker，task在这里执行；</li><li>Deploy mode ： cluster（driver在集群中，看不见输出结果。用于生产环境）、client（driver在客户端，能看见结果。用于开发测试）</li><li>Task：任务调度的最小单位，Driver将Task发送到Executor上执行；数量由分区数决定</li><li>Job：Action触发Job。Job包含多个stage；</li><li>Stage：依据shuffle（宽依赖），将一个Job切分为多个Stage，Stage又称为TaskSets；</li></ul><h1 id="Spark部署运行模式："><a href="#Spark部署运行模式：" class="headerlink" title="Spark部署运行模式："></a>Spark部署运行模式：</h1><p>本地模式：Spark所有进程都运行在一台机器的JVM中；<br>local、local[N]、local[*]、local[N,M]</p><p>伪分布式模式：在一台机器中模拟集群运行，相关的进程在同一台机器上；<br>local-cluster[N,cores,memory]</p><p>分布式模式包括：Standalone、Yarn、Mesos<br>spark://node1:7077</p><p>–deploy-mode：cluster、client(缺省值)<br>cluster：看不见返回结果，用于生产环境<br>client：能看见返回结果，用于测试环境<br>二者最主要的区别是：Driver运行在哪里。cluster模式，Driver运行在cluster上；client模式，Driver运行在客户机上；<br>standalone、Yarn都有cluster、client模式；</p><h1 id="RDD"><a href="#RDD" class="headerlink" title="RDD"></a>RDD</h1><p>RDD是spark的核心概念，它是一个容错、可以并行执行的分布式数据集。<br>什么是RDD：</p><ol><li>一个分区的列表</li><li>一个计算函数compute，对每个分区进行计算</li><li>对其他RDDs的依赖（宽依赖、窄依赖）列表</li><li>对key-value RDDs来说，存在一个分区器（Partitioner）【可选的】</li><li>对每个分区有一个优先位置的列表【可选的】</li></ol><h1 id="SparkContext"><a href="#SparkContext" class="headerlink" title="SparkContext"></a>SparkContext</h1><p>SparkContext是编写Spark程序用到的第一个类，是Spark的主要入口点,它负责和整个集群的交互;<br>SparkContext用于连接Spark集群、创建RDD、累加器、广播变量；</p><p>调用SparkContext的parallelize、makeRDD方法，从数组中创建RDD；<br>用textFile方法来从文件系统中加载数据创建RDD；</p><p>SparkContext的三大组件：DAGScheduler、TaskScheduler、SchedulerBackend<br>DAGScheduler  : 将DAG划分成若干个Stage；<br>TaskScheduler : 将Stage划分成若干为Task，并对Task进行调度；<br>SchedulerBackend：定义了许多与Executor事件相关的处理。如：新的executor注册时记录executor的信息，增加全局的资源量(核数)；executor更新状态，若任务完成的话，回收core；停止executor、remove executor等事件。</p><h1 id="RDD的操作"><a href="#RDD的操作" class="headerlink" title="RDD的操作"></a>RDD的操作</h1><p>可以分为：Transformation、Action<br>Transformation只是记录了RDD转换的轨迹，并不会发生真正的计算；<br>只有遇到Action操作时，才会发生真正的计算；</p><p>常见的Transformation：<br>会产生Shuffle的Transformation:<br>会产生action的Transformation:<br>常见的Action：</p><p>PairRDD常见操作：keys、values、sortByKey、reduceByKey、join、mapValues</p><h1 id="RDD的持久化"><a href="#RDD的持久化" class="headerlink" title="RDD的持久化"></a>RDD的持久化</h1><p>cache、persist、checkpoint：都属于Transformation，即都是lazy的，需要action触发；<br>cache() = persist(StorageLevel.MEMORY_ONLY)<br>StorageLevel.MEMORY_ONLY：默认的存储级别<br>StorageLevel.MEMORY_AND_DISK_2：本地放一份，远程放一份；<br>persist：可以有更多存储级别的选择；<br>cache、persist：主要用做性能优化；</p><p>checkpoint：主要用来做容错：将RDD中的数据存储保存到HFDS；斩断依赖；</p><p>persist中的数据会被自动清除；checkpoint的数据需要手工清除；</p><h1 id="RDD分区"><a href="#RDD分区" class="headerlink" title="RDD分区"></a>RDD分区</h1><p>RDD分区的原则：<br>尽可能使得分区的个数，等于集群核心数目；<br>尽可能使同一 RDD 不同分区内的记录的数量一致；</p><p>默认的分区数（并发数）(可在 spark-default.conf 配置)：<br>spark.default.parallelism</p><p>对于 textFile 方法，默认情况下：<br>每个HDFS的分区文件（默认块大小128M），每个都会创建一个RDD分区；最小2个分区；<br>对于本地文件，默认分区个数等于 min(defaultParallelism, 2)；</p><h1 id="分区器"><a href="#分区器" class="headerlink" title="分区器"></a>分区器</h1><p>Hash分区、Range分区、自定义分区；<br>只有Key-Value类型的RDD才会有分区器，非Key-Value类型的RDD分区器的值是None。<br>分区器决定了：</p><ul><li>RDD中分区的个数；</li><li>RDD中每条数据经过Shuffle过程属于哪个分区；</li><li>reduce的个数； </li></ul><h1 id="依赖"><a href="#依赖" class="headerlink" title="依赖"></a>依赖</h1><p>RDD的依赖分为两种：窄依赖(Narrow Dependencies)与宽依赖(Wide Dependencies，源码中称为Shuffle Dependencies)<br>依赖有2个作用：<br>其一用来解决数据容错；<br>其二用来划分stage。<br>窄依赖：父RDD的Partition 与 子RDDPartition对应的关系为 1:1 或 n:1；<br>宽依赖：父RDD的Partition 与 子RDDPartition对应的关系为 m:n ；<br>宽依赖对应着shuffle操作；<br>宽依赖中子RDD分区通常来自多个父RDD分区。如果子RDD的某个分区丢失，所有的父RDD分区可能都要进行重新计算；</p><h1 id="Shuffle"><a href="#Shuffle" class="headerlink" title="Shuffle"></a>Shuffle</h1><p>Hash Shuffle =&gt; Hash Shuffle V2 =&gt; Sort Shuffle =&gt; tungsten-sort =&gt; 两个shuffle算法的合并 =&gt; Hash Shuffle去除<br>Hash Shuffle 算法存在的问题：生成海量的小文件（同时打开过多文件 及 低效的随机IO）<br>reduceByKey、grouByKey ：都有shuffle，但reduceByKey在shuffle过程中传输的数据量小；<br>repartition、coalesce ：coalesce没有shuffle；repartition有shuffle；<br>shuffle是划分stage的依据；</p><h1 id="共享变量"><a href="#共享变量" class="headerlink" title="共享变量"></a>共享变量</h1><p>广播变量、累加器；<br>广播变量，由driver广播到Executor上；在Executor中的Task之间进行共享（减少了数据的传输）；共享变量只读；<br>累加器：则支持在所有不同节点之间进行累加计算，只能由driver读取；</p><h1 id="作业调度"><a href="#作业调度" class="headerlink" title="作业调度"></a>作业调度</h1><ol><li>SparkContext初始化；</li><li>Driver向Master注册，并申请资源；</li><li>Master命令Worker启动Executor；</li><li>Executor启动，并向Driver注册；</li><li>Driver向Executor发送Task；</li><li>Executor向Driver汇报任务执行情况；</li><li>应用程序执行完毕，Driver向Master注销自己；</li></ol><h1 id="SparkSQL"><a href="#SparkSQL" class="headerlink" title="SparkSQL"></a>SparkSQL</h1><p>SparkSession<br>RDD、Dataset、DataFrame</p><p>type DataFrame = Dataset[Row]<br>DataFrame = RDD[Row] + schema<br>Dataset = RDD + case class</p><p>spark.read.option(“”, true).csv(“”)<br>header、inferschema、delimiter(sep)</p><h2 id="Action"><a href="#Action" class="headerlink" title="Action"></a>Action</h2><p>show(n, false)<br>printSchema</p><h2 id="Transformation"><a href="#Transformation" class="headerlink" title="Transformation"></a>Transformation</h2><p>DSL（领域专用语言）<br>与RDD类似：map、flatMap、filter<br>缓存：cache、presist、checkpoint<br>select ：与列有关<br>where<br>groupBy<br>orderBy<br>join<br>空值处理<br>时间日期</p><h1 id="分析函数"><a href="#分析函数" class="headerlink" title="分析函数"></a>分析函数</h1><p>分析函数名(参数) over (<br>    partition by xxx<br>    order by xxx<br>    rows/range between … and …)</p><p>起始行 : unbounded preceding<br>终止行 : unbounded following<br>当前行 ：current row<br>前n行 ： n preceding<br>后n行 ： n following </p><p>聚组函数：min、max、sum、count、avg<br>排名函数：row_number、dense_rank、rank<br>行函数：lag、lead、first_value、last_value</p><p>其他：cube、rollup<br>记录的合并与展开 ： concat_ws、collect_set、collect_list、explode</p><p>半连接（left semi join）：左半连接实现了类似in、exists的查询语义，输出符合条件的左表内容;<br>反连接(left anti join)：两表关联，只返回主表的数据，并且只返回主表与子表没关联上的数据，这种连接就叫反连接。反连接一般就是指的 not in 和 not exists;</p><h1 id="Kafka-amp-Spark-Streaming"><a href="#Kafka-amp-Spark-Streaming" class="headerlink" title="Kafka &amp; Spark Streaming"></a>Kafka &amp; Spark Streaming</h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Spark简介&quot;&gt;&lt;a href=&quot;#Spark简介&quot; class=&quot;headerlink&quot; title=&quot;Spark简介&quot;&gt;&lt;/a&gt;Spark简介&lt;/h1&gt;&lt;img src=&quot;/2019/02/02/Spark最全笔记/spark特点_快速.png&quot; title
      
    
    </summary>
    
    
      <category term="Spark" scheme="http://yoursite.com/tags/Spark/"/>
    
  </entry>
  
</feed>
